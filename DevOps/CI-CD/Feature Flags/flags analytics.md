

## DB backend config system 


If youâ€™re managing **feature flags in a database (DB-backed config system)** rather than a managed platform like LaunchDarkly or AppConfig, youâ€™ll want to **build observability and analytics around feature usage yourself**.

Hereâ€™s a **complete, production-style explanation** of how to do it â€” crisp, structured, and with code-level examples ğŸ‘‡

---

# ğŸ§­ Overview

When using **DB-based Feature Flags**, you already have configuration control (CRUD for flags).  
Now, you need **observability**, which means tracking:

|Category|What to Measure|Why It Matters|
|---|---|---|
|**Usage Analytics**|How often each flag is evaluated / used|Understand real impact and adoption|
|**Exposure Tracking**|Who saw which flag or variant|Enable A/B test analysis|
|**Error & Performance Metrics**|Flag load latency, cache misses, etc.|Detect operational issues|
|**Change Auditing**|Who toggled the flag, when, and oldâ†’new value|Compliance & rollback history|
|**Health Signals**|Cache hit rates, DB reads, flag sync time|System reliability|

---

# âš™ï¸ 1ï¸âƒ£ Instrument Flag Evaluations (Feature Usage Analytics)

Each time your app **evaluates** a flag (i.e. checks `if feature_enabled(...)`), log an event to an analytics table or telemetry system.

### Example â€” Node.js (DB Flag Model)

```js
// pseudo-code for evaluating feature flag
async function isFeatureEnabled(userId, featureKey) {
  const flag = await db.flags.findOne({ key: featureKey });
  const enabled = flag.enabled;

  // track usage
  await db.featureUsage.insert({
    featureKey,
    userId,
    enabled,
    evaluatedAt: new Date(),
  });

  return enabled;
}
```

ğŸ”¹ Each evaluation is stored â€” later you can aggregate:

- Daily active flags
    
- Top-used features
    
- Adoption curves per feature
    

---

# ğŸ“Š 2ï¸âƒ£ Aggregate Metrics Periodically

To avoid flooding the DB, **batch events** or **stream to analytics backend** (Kafka, Kinesis, or OpenTelemetry exporter).

### Example: Aggregation Table Schema

| feature_key | date | total_evaluations | enabled_count | disabled_count |  
|--------------|------|------------------|----------------|  
| `new_checkout` | 2025-10-06 | 12,301 | 7,201 | 5,100 |

This can be updated every few minutes via cron or background worker.

---

# ğŸ” 3ï¸âƒ£ Exposure Tracking (Who Saw What)

For A/B rollouts or percentage rollouts, track **who got what version**.

```js
await db.featureExposure.insert({
  featureKey,
  userId,
  variant: selectedVariant,  // e.g., "A", "B", "control"
  rolloutPercent: 25,
  country: user.country,
  timestamp: new Date(),
});
```

âœ… Enables downstream analysis:

- Conversion rates by variant
    
- Engagement per rollout cohort
    
- Behavior-based tuning of rollout %
    

---

# ğŸªª 4ï¸âƒ£ Change Auditing (Toggle History)

Always audit **who changed flags** and **what changed**.

### Schema:

|id|feature_key|changed_by|old_value|new_value|changed_at|
|---|---|---|---|---|---|
|1|new_checkout|alice@dev|false|true|2025-10-05|

### Example Trigger:

```js
CREATE TRIGGER flag_audit_trigger
AFTER UPDATE ON feature_flags
FOR EACH ROW
INSERT INTO feature_audit(feature_key, changed_by, old_value, new_value, changed_at)
VALUES (NEW.key, SESSION_USER, OLD.enabled, NEW.enabled, NOW());
```

âœ… Enables rollback, traceability, and accountability.

---

# ğŸ“ˆ 5ï¸âƒ£ Operational Metrics (Health & Performance)

Use **application metrics** for observability â€” integrate with **Prometheus**, **Datadog**, or **OpenTelemetry**.

Track:

- **Flag fetch latency**
    
- **Cache hit/miss ratio**
    
- **Config sync delay**
    
- **Feature evaluation time**
    

### Example (OpenTelemetry):

```js
const { metrics } = require('@opentelemetry/api');

const featureEvalCounter = metrics.getMeter('feature-flags')
  .createCounter('feature_flag_evaluations', { description: 'Feature flag evaluations count' });

function recordEvaluation(featureKey) {
  featureEvalCounter.add(1, { feature: featureKey });
}
```

âœ… These show up in Grafana dashboards like:

- â€œFeature evaluation QPS per flagâ€
    
- â€œDB vs cache lookup ratioâ€
    
- â€œAverage latency per flag evaluationâ€
    

---

# ğŸ§  6ï¸âƒ£ Alerting & Dashboards

Once metrics flow in, set up **dashboards & alerts**:

|Alert|Threshold|Example Action|
|---|---|---|
|ğŸ”´ High DB latency|>200ms avg flag fetch|Check caching layer|
|âš ï¸ Feature toggle flaps|>3 changes/hour|Investigate toggle churn|
|âš™ï¸ Cache miss rate|>10%|Increase TTL or pre-warm cache|
|ğŸ“‰ Drop in flag eval count|-30% from avg|Possible code path regression|

---

# ğŸ§© 7ï¸âƒ£ Example Architecture (Self-managed Flags + Observability)

```
[App Service]
   â†“ (flag check)
[FeatureFlag Cache] â†â†’ [DB Flags Table]
   â†“ (metrics & usage events)
[Telemetry Collector] â†’ [Prometheus / Grafana]
[Event Stream] â†’ [Analytics DB / BigQuery]
[AUDIT LOG] â†’ [Change History Table]
```

âœ… **Realtime analytics**  
âœ… **Historical trends**  
âœ… **Auditable changes**  
âœ… **Full visibility** into rollout impact

---

# ğŸ§± 8ï¸âƒ£ Example Table Designs

### `feature_flags`

| id | key | enabled | rollout_percent | updated_at | updated_by |

### `feature_usage`

| id | feature_key | user_id | enabled | evaluated_at |

### `feature_exposure`

| id | feature_key | user_id | variant | rollout_percent | timestamp |

### `feature_audit`

| id | feature_key | old_value | new_value | changed_by | changed_at |

---

# ğŸš€ 9ï¸âƒ£ Modern Developer Practice

Today, developers often combine:

- **DB Flags** â†’ for config and control
    
- **Telemetry / OpenTelemetry** â†’ for metrics
    
- **ELK or BigQuery** â†’ for analytics
    
- **Grafana / Kibana** â†’ for visualization
    
- **Audit Table / Event Log** â†’ for compliance
    

This hybrid gives **LaunchDarkly-grade observability**, even in a self-hosted setup.

---

# ğŸ’¡ TL;DR

|Layer|What It Does|Implementation|
|---|---|---|
|**Evaluation Tracking**|Counts & outcomes|Insert / batch log|
|**Exposure Tracking**|Variant visibility|User-level logs|
|**Change Auditing**|Toggle history|DB triggers|
|**Performance Metrics**|Latency, cache hits|OpenTelemetry / Prometheus|
|**Dashboards & Alerts**|Visualization|Grafana, Datadog|

---




