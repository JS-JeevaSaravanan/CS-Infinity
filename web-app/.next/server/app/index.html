<!DOCTYPE html><html lang="en" class="h-full"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/a34f9d1faa5f3315-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/87b0a9fc77e88b3d.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-d6abbf1fcfdef890.js"/><script src="/_next/static/chunks/4bd1b696-7f4092adee896cfb.js" async=""></script><script src="/_next/static/chunks/517-96b93c00f993175a.js" async=""></script><script src="/_next/static/chunks/main-app-c7f07cb7520d6ebc.js" async=""></script><script src="/_next/static/chunks/app/layout-1843c2dad8a8caeb.js" async=""></script><script src="/_next/static/chunks/839-f703ec834851f667.js" async=""></script><script src="/_next/static/chunks/app/page-b31d2b1bb577579f.js" async=""></script><meta name="next-size-adjust"/><title>CS Infinity Notes</title><meta name="description" content="A collection of Computer Science and Programming notes"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_d65c78 h-full bg-gray-50 dark:bg-gray-900"><div class="min-h-full"><nav class="bg-white dark:bg-gray-800 shadow-sm"><div class="mx-auto max-w-7xl px-4 sm:px-6 lg:px-8"><div class="flex h-16 justify-between"><div class="flex"><div class="flex flex-shrink-0 items-center"><h1 class="text-xl font-bold text-gray-900 dark:text-white">CS Infinity</h1></div></div><div class="flex items-center"><button type="button" class="rounded-lg p-2.5 text-sm text-gray-500 hover:bg-gray-100 focus:outline-none focus:ring-4 focus:ring-gray-200 dark:text-gray-400 dark:hover:bg-gray-700 dark:focus:ring-gray-700" aria-label="Toggle dark mode"><svg class="h-5 w-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"></path></svg></button></div></div></div></nav><div class="flex h-full"><div class="hidden lg:fixed lg:inset-y-0 lg:flex lg:w-64 lg:flex-col"><div class="flex grow flex-col gap-y-5 overflow-y-auto border-r border-gray-200 bg-white px-6 pb-4"><div class="flex h-16 shrink-0 items-center"><span class="text-lg font-semibold">Categories</span></div><nav class="flex flex-1 flex-col"><ul role="list" class="flex flex-1 flex-col gap-y-7"><li><div class="text-xs font-semibold leading-6 text-gray-400">Famous algo</div><ul role="list" class="-mx-2 mt-2 space-y-1"><li><a class="text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold" href="#/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/0 Outline.md">0 Outline</a></li><li><a class="text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold" href="#/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Big O.md">Big O</a></li><li><a class="text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold" href="#/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Greedy.md">Greedy</a></li><li><a class="text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold" href="#/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Search.md">Search</a></li><li><a class="text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold" href="#/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Sort.md">Sort</a></li></ul></li><li><div class="text-xs font-semibold leading-6 text-gray-400">sorting</div><ul role="list" class="-mx-2 mt-2 space-y-1"><li><a class="text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold" href="#/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/sorting/Sort.md">Sort</a></li></ul></li><li><div class="text-xs font-semibold leading-6 text-gray-400">ORMs</div><ul role="list" class="-mx-2 mt-2 space-y-1"><li><a class="text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold" href="#/Users/jeevas/Documents/Jeeva/CS Infinity/CS/Backend/DB/ORMs/Stacks.md">Stacks</a></li></ul></li><li><div class="text-xs font-semibold leading-6 text-gray-400">CS</div><ul role="list" class="-mx-2 mt-2 space-y-1"><li><a class="text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold" href="#/Users/jeevas/Documents/Jeeva/CS Infinity/CS/CMD commands.md">CMD commands</a></li><li><a class="text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold" href="#/Users/jeevas/Documents/Jeeva/CS Infinity/CS/CS doubt.md">CS doubt</a></li><li><a class="text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold" href="#/Users/jeevas/Documents/Jeeva/CS Infinity/CS/Files running.md">Files running</a></li></ul></li></ul></nav></div></div><main class="py-10 lg:pl-72"><div class="px-4 sm:px-6 lg:px-8"><div class="mb-12"><h2 class="text-2xl font-bold mb-6 text-gray-900 dark:text-white">Famous algo</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article id="/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/0 Outline.md" class="bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6"><h3 class="text-xl font-semibold mb-4 text-gray-900 dark:text-white">0 Outline</h3><div class="prose dark:prose-invert prose-sm max-w-none"><p>Noted</p>
<p><a href="https://youtu.be/kp3fCihUXEg?si=lJoiiwBRlFpFtJu3">top 7 algo</a>
<a href="https://www.youtube.com/watch?v=4TUgqm2gJkE">bigO</a></p>
<p>[[Search]]
[[Famous algo/Sort]]
[[Greedy]]</p>
<p>[[Big O]]</p>
</div></article><article id="/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Big O.md" class="bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6"><h3 class="text-xl font-semibold mb-4 text-gray-900 dark:text-white">Big O</h3><div class="prose dark:prose-invert prose-sm max-w-none"><p>![[BigOGraph.png]]</p>
<p>Big O :</p>
<p>https://www.bigocheatsheet.com/</p>
<p>https://bigocheatsheet.io/</p>
<h3>Understanding Big O Notation</h3>
<p>Big O notation is a mathematical representation that describes the efficiency of an algorithm in terms of time complexity (how fast it runs) and space complexity (how much memory it uses). It provides a way to evaluate how the performance of an algorithm changes as the size of the input, denoted by ( n ), increases.</p>
<h4>Key Points of Big O Notation</h4>
<ol>
<li><strong>Definition</strong>: Big O expresses the upper bound of an algorithm’s running time or space requirement, allowing us to compare efficiencies.</li>
<li><strong>Variables</strong>: The variable ( n ) represents the number of inputs. For example, if you have an array of 5 elements, ( n = 5 ).</li>
<li><strong>Growth Rates</strong>: Algorithms with lower growth rates (e.g., ( O(1) ), ( O(\log n) )) are generally more efficient than those with higher growth rates (e.g., ( O(n) ), ( O(n^2) )).</li>
</ol>
<h4>Common Big O Functions (Best to Worst)</h4>
<ul>
<li>( O(1) ): Constant time</li>
<li>( O(\log n) ): Logarithmic time</li>
<li>( O(n) ): Linear time</li>
<li>( O(n \log n) ): Linearithmic time</li>
<li>( O(n^2) ): Quadratic time</li>
<li>( O(2^n) ): Exponential time</li>
<li>( O(n!) ): Factorial time</li>
</ul>
<h3>Example: Comparing Algorithms</h3>
<p>Let’s illustrate why Big O notation is important with an example involving two algorithms:</p>
<ul>
<li><strong>Algorithm A</strong>: ( O(\log n) )</li>
<li><strong>Algorithm B</strong>: ( O(n) )</li>
</ul>
<h4>Scenario 1: Analyzing 10 Elements</h4>
<p>For ( n = 10 ):</p>
<ul>
<li>( O(\log(10)) ) ≈ 3.3 milliseconds</li>
<li>( O(10) ) = 10 milliseconds</li>
</ul>
<p>With 10 elements, the difference in speed is noticeable but might not matter significantly in practice.</p>
<h4>Scenario 2: Analyzing 10 Million Elements</h4>
<p>Now consider ( n = 10,000,000 ):</p>
<ul>
<li>( O(\log(10,000,000)) ) ≈ 23.3 milliseconds</li>
<li>( O(10,000,000) ) = 10,000,000 milliseconds (or about 2 hours and 47 minutes)</li>
</ul>
<p>In this scenario, the performance gap becomes critical. A delay of 2 hours for a search engine would be unacceptable.</p>
<h3>Conclusion</h3>
<p>Understanding Big O notation helps you evaluate algorithms' performance and make informed decisions when selecting the right algorithm for your project. As seen, even a small difference in complexity can lead to vastly different performance outcomes with larger datasets.</p>
<p>If you're interested in diving deeper, consider exploring resources that detail the complexities of various data structures and algorithms. This foundational knowledge is invaluable for software engineering and algorithm design!</p>
</div></article><article id="/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Greedy.md" class="bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6"><h3 class="text-xl font-semibold mb-4 text-gray-900 dark:text-white">Greedy</h3><div class="prose dark:prose-invert prose-sm max-w-none"><h2>Greedy Algorithms: An Overview</h2>
<p>Greedy algorithms are designed to make the most favorable choice at each step in order to find a solution. This approach can be efficient for specific problems but may not always yield the optimal solution. Let’s explore when to use greedy algorithms, along with an example of their strengths and weaknesses.</p>
<h4>Key Characteristics of Greedy Algorithms</h4>
<ol>
<li><strong>Local Optimality</strong>: At each decision point, the algorithm makes the best local choice without considering the broader consequences.</li>
<li><strong>Efficiency</strong>: Greedy algorithms typically have lower time complexity since they don’t evaluate every possible outcome.</li>
<li><strong>Not Always Optimal</strong>: While they can be efficient, greedy algorithms do not guarantee an optimal solution for all problems.</li>
</ol>
<h3>When Not to Use Greedy Algorithms</h3>
<p>Greedy algorithms are ineffective in scenarios where making a locally optimal choice does not lead to a globally optimal solution. For example, consider a pathfinding problem where each decision incurs a cost:</p>
<ul>
<li><strong>Example</strong>: Imagine you have a set of paths with different costs:
<ul>
<li>Path A: $7</li>
<li>Path B: $8</li>
<li>Path C: $9</li>
<li>Path D: $10</li>
</ul>
</li>
</ul>
<p>If you use a greedy algorithm, it might choose Path A ($7) first, then Path C ($9), resulting in a total cost of $16. However, the optimal path might only cost $3 by taking a different route entirely.</p>
<h3>When to Use Greedy Algorithms</h3>
<p>Greedy algorithms are suitable for problems where:</p>
<ul>
<li>An approximate solution is acceptable.</li>
<li>The problem exhibits optimal substructure, meaning the optimal solution to a problem can be constructed from optimal solutions of its subproblems.</li>
</ul>
<h4>Famous Example: The Traveling Salesman Problem (TSP)</h4>
<p>The TSP asks for the shortest possible route that visits each city exactly once and returns to the starting point. Given the factorial growth of potential routes, the total number of paths becomes infeasible to calculate for larger datasets:</p>
<ul>
<li>For 5 cities: ( (n-1)!/2 = 12 ) routes.</li>
<li>For 10 cities: ( 181,440 ) routes.</li>
<li>For 50 cities: ( 304140932017133780436126081660647688443776415689605120000000000 ) routes.</li>
</ul>
<p>Given such exponential growth, finding an optimal solution using brute force is impractical. Here’s where a greedy approach can be beneficial:</p>
<ol>
<li><strong>Starting Point</strong>: Choose an arbitrary starting city.</li>
<li><strong>Next City</strong>: Always select the nearest unvisited city.</li>
<li><strong>Completion</strong>: Repeat until all cities are visited, then return to the starting city.</li>
</ol>
<p>While this approach doesn’t guarantee the optimal route, it provides a practical solution that is significantly faster than evaluating all possible paths.</p>
<h3>Summary</h3>
<p>Greedy algorithms excel in scenarios where:</p>
<ul>
<li>An exact optimal solution is infeasible due to the problem’s complexity.</li>
<li>A reasonable approximation is acceptable.</li>
</ul>
<p>They are best applied to problems that allow for a step-by-step decision-making process leading to a satisfactory solution. Understanding when and how to implement these algorithms can enhance problem-solving efficiency in various computational tasks. If you have more questions or want further clarification on specific examples, feel free to ask!</p>
</div></article><article id="/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Search.md" class="bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6"><h3 class="text-xl font-semibold mb-4 text-gray-900 dark:text-white">Search</h3><div class="prose dark:prose-invert prose-sm max-w-none"><h2>Binary Search</h2>
<p>Binary search is an efficient algorithm for finding the position of a specific element in a <strong>sorted</strong> list. Let’s illustrate this with a guessing game example:</p>
<p>Imagine your friend chooses a number between <strong>1 and 100</strong>, and your task is to guess it.</p>
<h4>Linear Search</h4>
<p>One approach is <strong>linear search</strong>, where you start at <strong>1</strong> and guess each number in sequence. If the correct number is <strong>100</strong>, you’d need <strong>100 guesses</strong>—which is inefficient, especially with larger ranges (like <strong>1 to 10,000</strong>). This method has a time complexity of <strong>O(n)</strong>, meaning the number of guesses grows linearly with the size of the list.</p>
<h4>Binary Search</h4>
<p>Now, let’s consider <strong>binary search</strong>. Instead of starting at <strong>1</strong>, you begin by guessing the <strong>middle</strong> of the range, which is <strong>50</strong>. Your friend then tells you if the number is higher or lower. Based on that feedback, you can eliminate half of the remaining possibilities with each guess.</p>
<p>For instance:</p>
<ol>
<li>Guess <strong>50</strong>: If the number is higher, you now consider <strong>51 to 100</strong>.</li>
<li>Guess the new middle (let's say <strong>75</strong>): Continue narrowing down the range based on feedback.</li>
</ol>
<p>This method effectively halves the number of options with each guess, leading to a time complexity of <strong>O(log n)</strong>.</p>
<pre><code class="language-pseudo">FUNCTION binarySearch(array, target):
    low = 0
    high = length(array) - 1

    WHILE low &#x3C;= high:
        mid = (low + high) // 2  // Integer division

        IF array[mid] == target:
            RETURN mid  // Target found
        ELSE IF array[mid] &#x3C; target:
            low = mid + 1  // Search in the right half
        ELSE:
            high = mid - 1  // Search in the left half

    RETURN -1  // Target not found

</code></pre>
<h4>Worst-Case Comparison</h4>
<p>To see how efficient this is, let’s look at the worst-case scenario:</p>
<ul>
<li>For linear search in the range <strong>1 to 10,000</strong>, you might need <strong>10,000 guesses</strong>.</li>
<li>For binary search, using <strong>O(log n)</strong>:
<ul>
<li>Calculate ( \log_2(10,000) ), which is approximately <strong>13.3</strong>. Thus, you’d need <strong>14 guesses</strong> in the worst case.</li>
</ul>
</li>
</ul>
<h4>Conclusion</h4>
<p>Binary search is a powerful tool, particularly when dealing with sorted lists. Its efficiency makes it significantly faster than linear search for large datasets. Just remember: binary search only works on sorted data. If you find yourself needing to search through a sorted list, binary search is an excellent approach to consider.</p>
<h2>Depth-First Search (DFS)</h2>
<p>Depth-First Search (DFS) is a traversal algorithm used to explore nodes and edges in a graph or tree structure. The key idea behind DFS is to start at the <strong>root node</strong> and explore as far down one branch as possible before backtracking. This approach effectively utilizes a technique called <strong>backtracking</strong>.</p>
<h4>How DFS Works</h4>
<ol>
<li>
<p><strong>Initialization</strong>: Before starting DFS, create a <strong>visited array</strong> to keep track of nodes you’ve already explored.</p>
</li>
<li>
<p><strong>Traversal</strong>:</p>
<ul>
<li>Begin at the <strong>root node</strong> and add it to the visited array.</li>
<li>Move to the first child node and add it to the visited array.</li>
<li>Continue down this branch, visiting nodes and adding them to the visited array until you reach a node with no unvisited children.</li>
</ul>
</li>
<li>
<p><strong>Backtracking</strong>:</p>
<ul>
<li>Once you hit a dead end, backtrack to the previous node and check for any unvisited children.</li>
<li>If there are unvisited nodes, proceed down that branch and repeat the process.</li>
<li>If not, backtrack further up until all nodes have been visited.</li>
</ul>
</li>
</ol>
<p>This process continues until the entire graph has been explored.</p>
<h4>Visual Example</h4>
<p>Imagine navigating a maze: you start at the entrance and explore each path to its end. If you encounter a wall, you backtrack to the last junction and try another path. This method of exploration allows you to efficiently search through complex structures.</p>
<p>Recursive DFS Pseudocode</p>
<pre><code class="language-pseudo">FUNCTION DFS(node, visited):
    IF node IS NULL:
        RETURN

    // Mark the node as visited
    visited.add(node)

    // Process the current node (e.g., print it)
    PRINT(node)

    // Recur for each unvisited adjacent node
    FOR each neighbor in node.adjacent:
        IF neighbor NOT IN visited:
            DFS(neighbor, visited)

</code></pre>
<p>Iterative DFS Pseudocode</p>
<pre><code class="language-pseudo">FUNCTION iterativeDFS(root):
    visited = empty set
    stack = empty stack

    stack.push(root)

    WHILE stack is not empty:
        node = stack.pop()

        IF node NOT IN visited:
            visited.add(node)

            // Process the current node (e.g., print it)
            PRINT(node)

            // Add all unvisited neighbors to the stack
            FOR each neighbor in node.adjacent:
                IF neighbor NOT IN visited:
                    stack.push(neighbor)

</code></pre>
<h4>Time Complexity</h4>
<p>The time complexity of DFS is expressed as <strong>O(V + E)</strong>, where:</p>
<ul>
<li><strong>V</strong> is the total number of <strong>vertices</strong> (or nodes).</li>
<li><strong>E</strong> is the total number of <strong>edges</strong> (or branches).</li>
</ul>
<p>This complexity arises because, in the worst case, you may need to visit every node and edge.</p>
<h4>Real-World Applications</h4>
<p>DFS is particularly useful in scenarios like:</p>
<ul>
<li><strong>Maze solving</strong>: Finding a path through a maze by exploring all possible routes.</li>
<li><strong>Puzzle solving</strong>: Games like Sudoku, where exploring different configurations is necessary.</li>
<li><strong>Graph algorithms</strong>: Such as topological sorting and finding connected components.</li>
</ul>
<p>Now that we’ve covered DFS, let’s move on to its counterpart: <strong>Breadth-First Search (BFS)</strong>.</p>
<h2>Breadth-First Search (BFS)</h2>
<p>Breadth-First Search (BFS) is an algorithm used to explore nodes and edges in a graph or tree structure. Unlike Depth-First Search (DFS), BFS explores all the nodes at the current level before moving on to the next level. This level-by-level approach makes it intuitive and easy to understand.</p>
<h4>How BFS Works</h4>
<ol>
<li>
<p><strong>Initialization</strong>:</p>
<ul>
<li>Create a <strong>visited array</strong> to track which nodes have been explored.</li>
<li>Create a <strong>queue</strong> to hold the nodes that need to be explored.</li>
</ul>
</li>
<li>
<p><strong>Traversal</strong>:</p>
<ul>
<li>Start at the <strong>root node</strong>, mark it as visited, and add it to the queue.</li>
<li>While the queue is not empty:
<ul>
<li>Dequeue the front node.</li>
<li>Process that node (e.g., print it or store it).</li>
<li>Enqueue all its unvisited neighbors, marking them as visited as you go.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Level-by-Level Exploration</strong>:</p>
<ul>
<li>Continue this process until all reachable nodes have been visited, ensuring that you explore each level fully before proceeding to the next.</li>
</ul>
</li>
</ol>
<h4>Visual Example</h4>
<p>Think of BFS like exploring a building floor by floor. You check every room on the first floor before moving to the second floor. This systematic approach ensures that you see all possible connections at each level.</p>
<h4>Real-World Applications</h4>
<p>BFS is commonly used in scenarios such as:</p>
<ul>
<li><strong>Chess algorithms</strong>: To evaluate possible moves by exploring all possible next moves and their subsequent options.</li>
<li><strong>Social networking</strong>: Finding the shortest path between users.</li>
<li><strong>Web crawling</strong>: To explore web pages level by level.</li>
</ul>
<h4>Time Complexity</h4>
<p>The time complexity of BFS is also <strong>O(V + E)</strong>, where:</p>
<ul>
<li><strong>V</strong> is the total number of vertices (nodes).</li>
<li><strong>E</strong> is the total number of edges (connections).</li>
</ul>
<h3>Pseudocode for Breadth-First Search</h3>
<pre><code class="language-plaintext">FUNCTION BFS(root):
    visited = empty set
    queue = empty queue

    // Start with the root node
    visited.add(root)
    queue.enqueue(root)

    WHILE queue is not empty:
        node = queue.dequeue()

        // Process the current node (e.g., print it)
        PRINT(node)

        // Enqueue all unvisited neighbors
        FOR each neighbor in node.adjacent:
            IF neighbor NOT IN visited:
                visited.add(neighbor)
                queue.enqueue(neighbor)
</code></pre>
<h3>Summary</h3>
<ul>
<li><strong>BFS</strong> efficiently explores nodes level by level, ensuring that all neighbors are examined before moving deeper.</li>
<li>The algorithm is particularly useful for problems requiring the shortest path or level-based exploration.</li>
</ul>
<p>If you have any further questions or need more examples, feel free to ask!</p>
</div></article><article id="/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Sort.md" class="bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6"><h3 class="text-xl font-semibold mb-4 text-gray-900 dark:text-white">Sort</h3><div class="prose dark:prose-invert prose-sm max-w-none"><h2>Insertion Sort Explained</h2>
<p><strong>Insertion Sort</strong> is a straightforward and intuitive sorting algorithm. It builds a sorted array (or list) one element at a time by repeatedly taking an unsorted element and inserting it into its correct position within the sorted portion of the array.</p>
<h4>How Insertion Sort Works</h4>
<ol>
<li>
<p><strong>Start with the first element</strong>: Consider the first element as a sorted portion.</p>
</li>
<li>
<p><strong>Compare and Insert</strong>:</p>
<ul>
<li>Take the next element in the unsorted portion.</li>
<li>Compare it with elements in the sorted portion, moving from right to left.</li>
<li>If the current element is smaller than the compared element, shift the compared element to the right.</li>
<li>Insert the current element in its correct position once you find the right spot.</li>
</ul>
</li>
<li>
<p><strong>Repeat</strong>: Continue this process for all elements in the list until the entire array is sorted.</p>
</li>
</ol>
<h4>Example</h4>
<p>Let’s say we have the following list: <code>[5, 2, 9, 1, 5, 6]</code>.</p>
<ul>
<li>Start with the first element (5). It’s already sorted.</li>
<li>Compare 2 with 5; since 2 &#x3C; 5, swap them. The list is now <code>[2, 5, 9, 1, 5, 6]</code>.</li>
<li>Compare 9 with 5; since 9 > 5, leave it.</li>
<li>Compare 1 with 9; since 1 &#x3C; 9, shift 9 to the right. Now compare with 5; shift 5 to the right. Insert 1. The list is now <code>[1, 2, 5, 9, 5, 6]</code>.</li>
<li>Continue this process until the list is fully sorted.</li>
</ul>
<h4>Time Complexity</h4>
<ul>
<li><strong>Best Case</strong>: <strong>O(n)</strong>, which occurs when the list is already sorted. The algorithm makes a single pass through the list.</li>
<li><strong>Worst Case</strong>: <strong>O(n²)</strong>, which occurs when the list is in reverse order. Each element has to be compared with every other element.</li>
<li><strong>Average Case</strong>: <strong>O(n²)</strong>, typical for randomly ordered lists.</li>
</ul>
<h4>When to Use Insertion Sort</h4>
<ul>
<li><strong>Mostly Sorted Lists</strong>: Insertion sort performs well when the list is nearly sorted, as it can achieve linear time complexity.</li>
<li><strong>Small Lists</strong>: Due to its simplicity and low overhead, it’s efficient for small datasets.</li>
<li><strong>Stability</strong>: Insertion sort is a stable sort, meaning that it preserves the relative order of equal elements.</li>
</ul>
<h3>Pseudocode for Insertion Sort</h3>
<pre><code class="language-plaintext">FUNCTION insertionSort(array):
    FOR i FROM 1 TO length(array) - 1:
        key = array[i]
        j = i - 1

        // Move elements of array[0..i-1] that are greater than key
        WHILE j >= 0 AND array[j] > key:
            array[j + 1] = array[j]
            j = j - 1

        array[j + 1] = key  // Insert key into its correct position
</code></pre>
<h3>Summary</h3>
<p>Insertion Sort is an effective algorithm for small or nearly sorted datasets. While it may not be suitable for large lists due to its O(n²) worst-case runtime, it is easy to implement and understand, making it a good choice for certain scenarios. If you have more questions or need further examples, feel free to ask!</p>
<h3>Insertion Sort vs. Merge Sort</h3>
<h4>Insertion Sort Overview</h4>
<p><strong>Insertion Sort</strong> is a simple sorting algorithm that builds a sorted array one element at a time. Here’s a quick recap of its performance:</p>
<ul>
<li><strong>Best Case</strong>: <strong>O(n)</strong> when the array is already sorted, as it only requires a single pass through the elements.</li>
<li><strong>Worst Case</strong>: <strong>O(n²)</strong> when the array is in reverse order, necessitating comparisons with every other element.</li>
<li><strong>Use Cases</strong>: Best for small or nearly sorted lists due to its simplicity and efficiency in those scenarios.</li>
</ul>
<h2>Merge Sort Overview</h2>
<p><strong>Merge Sort</strong> is a more advanced sorting algorithm that uses the <strong>divide-and-conquer</strong> strategy. It efficiently handles larger and more complex datasets. Here’s how it works:</p>
<ol>
<li>
<p><strong>Divide</strong>: Split the array into two halves. This process continues recursively until each subarray contains a single element.</p>
</li>
<li>
<p><strong>Conquer</strong>: Merge the sorted subarrays back together. During this process, compare the elements from each half and sort them as you combine them.</p>
</li>
<li>
<p><strong>Combine</strong>: The merging process continues until the entire array is reconstructed in sorted order.</p>
</li>
</ol>
<h4>Visualization of Merge Sort</h4>
<p>Imagine you have an array <code>[38, 27, 43, 3, 9, 82, 10]</code>:</p>
<ol>
<li>
<p><strong>Splitting</strong>:</p>
<ul>
<li>First, split into <code>[38, 27, 43]</code> and <code>[3, 9, 82, 10]</code>.</li>
<li>Split further until you reach single elements: <code>[38]</code>, <code>[27]</code>, <code>[43]</code>, <code>[3]</code>, <code>[9]</code>, <code>[82]</code>, <code>[10]</code>.</li>
</ul>
</li>
<li>
<p><strong>Merging</strong>:</p>
<ul>
<li>Merge pairs: <code>[27, 38]</code>, <code>[3, 9, 10, 82]</code>, <code>[43]</code>.</li>
<li>Continue merging while sorting: <code>[27, 38, 43]</code> and <code>[3, 9, 10, 82]</code>.</li>
<li>Finally, combine to get the fully sorted array: <code>[3, 9, 10, 27, 38, 43, 82]</code>.</li>
</ul>
</li>
</ol>
<h4>Time Complexity</h4>
<ul>
<li><strong>Merge Sort</strong>: Both best and worst-case time complexity is <strong>O(n log n)</strong>. This efficiency makes it suitable for large datasets.</li>
<li><strong>Insertion Sort vs. Merge Sort</strong>:
<ul>
<li>For small or mostly sorted lists, Insertion Sort is more efficient (O(n)).</li>
<li>For larger, unsorted lists, Merge Sort is preferable due to its O(n log n) runtime, which remains consistent regardless of initial order.</li>
</ul>
</li>
</ul>
<h3>Summary</h3>
<ul>
<li><strong>Insertion Sort</strong>: Effective for small or nearly sorted lists with a best-case of O(n) but poor performance on larger datasets (O(n²)).</li>
<li><strong>Merge Sort</strong>: Ideal for larger or more unordered lists, consistently performing at O(n log n), leveraging the power of recursion and divide-and-conquer.</li>
</ul>
<p>Understanding these algorithms allows you to choose the right one based on the size and initial order of the dataset you're working with. If you have any further questions or need additional examples, feel free to ask!</p>
<p>Here’s the pseudocode for <strong>Merge Sort</strong>:</p>
<h3>Merge Sort Pseudocode</h3>
<pre><code class="language-plaintext">FUNCTION mergeSort(array):
    IF length(array) &#x3C;= 1:
        RETURN array  // Base case: an array of zero or one element is already sorted

    // Divide the array into two halves
    mid = length(array) // 2
    left = mergeSort(array[0:mid])    // Recursively sort the left half
    right = mergeSort(array[mid:end])  // Recursively sort the right half

    // Merge the sorted halves
    RETURN merge(left, right)

FUNCTION merge(left, right):
    result = empty array
    i = 0  // Pointer for left array
    j = 0  // Pointer for right array

    // Merge elements from both arrays in sorted order
    WHILE i &#x3C; length(left) AND j &#x3C; length(right):
        IF left[i] &#x3C;= right[j]:
            result.append(left[i])
            i = i + 1
        ELSE:
            result.append(right[j])
            j = j + 1

    // Append any remaining elements from left array
    WHILE i &#x3C; length(left):
        result.append(left[i])
        i = i + 1

    // Append any remaining elements from right array
    WHILE j &#x3C; length(right):
        result.append(right[j])
        j = j + 1

    RETURN result  // Return the merged and sorted array
</code></pre>
<h3>Explanation</h3>
<ol>
<li><strong>Base Case</strong>: If the array has one or no elements, it’s already sorted.</li>
<li><strong>Divide</strong>: The array is split into two halves.</li>
<li><strong>Conquer</strong>: Each half is sorted recursively using <code>mergeSort</code>.</li>
<li><strong>Merge</strong>: The sorted halves are combined into a single sorted array using the <code>merge</code> function.</li>
</ol>
<p>This pseudocode clearly outlines how Merge Sort operates, utilizing recursion and the merging process to achieve efficient sorting. If you have more questions or need further details, just let me know!</p>
<h2>Quick Sort Overview</h2>
<p><strong>Quick Sort</strong> is a powerful and efficient sorting algorithm that follows the <strong>divide-and-conquer</strong> strategy. It's known for its speed in practical scenarios, making it one of the most commonly used sorting algorithms, despite its potential for poor performance in specific cases.</p>
<h4>How Quick Sort Works</h4>
<ol>
<li>
<p><strong>Choose a Pivot</strong>:</p>
<ul>
<li>Select a pivot element from the array. The ideal choice is a value close to the median, as this helps to balance the partitions.</li>
</ul>
</li>
<li>
<p><strong>Partitioning</strong>:</p>
<ul>
<li>Rearrange the array so that elements less than the pivot come before it and elements greater than the pivot come after it. This process is called partitioning.</li>
<li>The pivot is then placed in its correct position in the sorted array.</li>
</ul>
</li>
<li>
<p><strong>Recursion</strong>:</p>
<ul>
<li>Recursively apply the above steps to the sub-arrays formed by partitioning (the left sub-array and the right sub-array).</li>
</ul>
</li>
<li>
<p><strong>Base Case</strong>:</p>
<ul>
<li>The recursion ends when the sub-arrays have one or no elements, as they are already sorted.</li>
</ul>
</li>
</ol>
<h4>Visualization Example</h4>
<ol>
<li>Start with the array: <code>[10, 7, 8, 9, 1, 5]</code>.</li>
<li>Select a pivot (e.g., <code>8</code>). Move it to the end of the list: <code>[10, 7, 9, 1, 5, 8]</code>.</li>
<li>Set pointers at the leftmost and rightmost ends:
<ul>
<li>Compare elements and swap as needed to ensure all elements left of the pivot are less than it, and all elements right are greater.</li>
</ul>
</li>
<li>Once the pointers cross, place the pivot in its correct position. The array might look like: <code>[7, 5, 1, 8, 10, 9]</code>.</li>
<li>Recursively apply the same steps to the sub-arrays <code>[7, 5, 1]</code> and <code>[10, 9]</code>.</li>
</ol>
<h4>Time Complexity</h4>
<ul>
<li><strong>Best Case</strong>: <strong>O(n log n)</strong> when the pivot divides the array into two equal halves.</li>
<li><strong>Average Case</strong>: <strong>O(n log n)</strong>; this is where Quick Sort shines.</li>
<li><strong>Worst Case</strong>: <strong>O(n²)</strong> occurs when the smallest or largest element is consistently chosen as the pivot (e.g., already sorted arrays).</li>
</ul>
<h4>Space Complexity</h4>
<ul>
<li><strong>Quick Sort</strong>: <strong>O(log n)</strong> due to the recursive stack space.</li>
<li><strong>Merge Sort</strong>: <strong>O(n)</strong> due to the need for temporary arrays during the merge process.</li>
</ul>
<h3>Why Use Quick Sort?</h3>
<ul>
<li><strong>Speed</strong>: On average, Quick Sort tends to be faster than both Insertion Sort and Merge Sort due to its efficient in-place partitioning.</li>
<li><strong>Memory Efficiency</strong>: Uses less memory than Merge Sort.</li>
<li><strong>Performance Tuning</strong>: With careful implementation (like choosing good pivots), it can avoid worst-case scenarios.</li>
</ul>
<h3>Pseudocode for Quick Sort</h3>
<pre><code class="language-plaintext">FUNCTION quickSort(array, low, high):
    IF low &#x3C; high:
        // Partition the array and get the pivot index
        pivotIndex = partition(array, low, high)

        // Recursively sort elements before and after the partition
        quickSort(array, low, pivotIndex - 1)
        quickSort(array, pivotIndex + 1, high)

FUNCTION partition(array, low, high):
    pivot = array[high]  // Choose the last element as the pivot
    i = low - 1          // Pointer for the smaller element

    FOR j FROM low TO high - 1:
        IF array[j] &#x3C;= pivot:
            i = i + 1
            swap(array[i], array[j])  // Swap if element is smaller than the pivot

    swap(array[i + 1], array[high])  // Swap the pivot into the correct position
    RETURN i + 1  // Return the partition index
</code></pre>
<h3>Summary</h3>
<ul>
<li><strong>Quick Sort</strong> is an efficient, recursive, divide-and-conquer algorithm that, when implemented correctly, is typically faster than other sorting algorithms on average.</li>
<li>Understanding its mechanics and proper implementation is crucial, as even minor mistakes can lead to inefficiencies.</li>
<li>Its low space complexity makes it a favorable choice for large datasets.</li>
</ul>
<p>If you have more questions or need additional explanations, feel free to ask!</p>
</div></article></div></div><div class="mb-12"><h2 class="text-2xl font-bold mb-6 text-gray-900 dark:text-white">sorting</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article id="/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/sorting/Sort.md" class="bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6"><h3 class="text-xl font-semibold mb-4 text-gray-900 dark:text-white">Sort</h3><div class="prose dark:prose-invert prose-sm max-w-none"><p>sorting olympics</p>
<p>https://www.youtube.com/watch?v=N4JVT3eVBP8</p>
</div></article></div></div><div class="mb-12"><h2 class="text-2xl font-bold mb-6 text-gray-900 dark:text-white">ORMs</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article id="/Users/jeevas/Documents/Jeeva/CS Infinity/CS/Backend/DB/ORMs/Stacks.md" class="bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6"><h3 class="text-xl font-semibold mb-4 text-gray-900 dark:text-white">Stacks</h3><div class="prose dark:prose-invert prose-sm max-w-none"><p>Object-Relational Mappers (ORMs) are tools that help developers interact with databases using object-oriented programming languages. Here’s a list of some of the most popular ORMs in various programming languages:</p>
<h3>Python</h3>
<ol>
<li>
<p><strong>SQLAlchemy</strong></p>
<ul>
<li>A powerful and flexible ORM that provides a full suite of well-known enterprise-level persistence patterns. It supports both high-level ORM capabilities and low-level database interaction.</li>
</ul>
</li>
<li>
<p><strong>Django ORM</strong></p>
<ul>
<li>Built into the Django web framework, it allows developers to interact with databases using Python objects and provides a powerful query language.</li>
</ul>
</li>
<li>
<p><strong>Peewee</strong></p>
<ul>
<li>A small and expressive ORM that is easy to use and well-suited for small projects or applications that don’t need the full complexity of SQLAlchemy.</li>
</ul>
</li>
</ol>
<h3>JavaScript</h3>
<ol>
<li>
<p><strong>Sequelize</strong></p>
<ul>
<li>A promise-based ORM for Node.js that supports multiple SQL dialects like PostgreSQL, MySQL, and SQLite. It features migrations, model validation, and associations.</li>
</ul>
</li>
<li>
<p><strong>TypeORM</strong></p>
<ul>
<li>An ORM for TypeScript and JavaScript (ES7, ES6, ES5) that supports Active Record and Data Mapper patterns. It works with various databases and is great for TypeScript projects.</li>
</ul>
</li>
<li>
<p><strong>Mongoose</strong></p>
<ul>
<li>An ODM (Object Data Modeling) library for MongoDB and Node.js, providing a schema-based solution to model application data.</li>
</ul>
</li>
</ol>
<h3>Ruby</h3>
<ol>
<li>
<p><strong>Active Record</strong></p>
<ul>
<li>The default ORM for Ruby on Rails, it provides a straightforward way to interact with databases and supports features like migrations, validations, and associations.</li>
</ul>
</li>
<li>
<p><strong>Sequel</strong></p>
<ul>
<li>A simple, flexible ORM for Ruby that supports multiple databases and offers a powerful query DSL.</li>
</ul>
</li>
</ol>
<h3>PHP</h3>
<ol>
<li>
<p><strong>Eloquent</strong></p>
<ul>
<li>The ORM included with the Laravel framework. It provides an elegant and expressive syntax for working with databases and includes support for relationships, eager loading, and more.</li>
</ul>
</li>
<li>
<p><strong>Doctrine</strong></p>
<ul>
<li>A powerful ORM for PHP that supports complex data models and is used widely in Symfony applications.</li>
</ul>
</li>
</ol>
<h3>C#</h3>
<ol>
<li>
<p><strong>Entity Framework</strong></p>
<ul>
<li>A popular ORM for .NET applications that supports both Code First and Database First approaches. It provides a rich set of features for querying and updating databases.</li>
</ul>
</li>
<li>
<p><strong>Dapper</strong></p>
<ul>
<li>A lightweight ORM for .NET that focuses on performance. It’s not as feature-rich as Entity Framework but is very fast and suitable for simple scenarios.</li>
</ul>
</li>
</ol>
<h3>Go</h3>
<ol>
<li>
<p><strong>GORM</strong></p>
<ul>
<li>An ORM for Go that provides an easy way to interact with databases and supports associations, hooks, and migrations.</li>
</ul>
</li>
<li>
<p><strong>Ent</strong></p>
<ul>
<li>An ORM for Go that focuses on code generation and type safety, making it easy to work with complex data models.</li>
</ul>
</li>
</ol>
<h3>Conclusion</h3>
<p>When choosing an ORM, consider the following:</p>
<ul>
<li><strong>Project Requirements</strong>: Some ORMs are better suited for complex applications, while others are lightweight for simpler projects.</li>
<li><strong>Database Support</strong>: Ensure the ORM supports the database system you plan to use.</li>
<li><strong>Community and Documentation</strong>: A strong community and good documentation can make a big difference in development speed and troubleshooting.</li>
</ul>
<p>Ultimately, the best ORM for your project will depend on your specific needs, the programming language you're using, and the overall architecture of your application.</p>
</div></article></div></div><div class="mb-12"><h2 class="text-2xl font-bold mb-6 text-gray-900 dark:text-white">CS</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article id="/Users/jeevas/Documents/Jeeva/CS Infinity/CS/CMD commands.md" class="bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6"><h3 class="text-xl font-semibold mb-4 text-gray-900 dark:text-white">CMD commands</h3><div class="prose dark:prose-invert prose-sm max-w-none"><p>Terminal linux commands:
To create a folder</p>
<pre><code class="language-bash">mkdir folder_name  
</code></pre>
<p>If you want to create a folder in a specific directory, navigate to that directory using the <code>cd</code> command first:</p>
<pre><code class="language-bash">cd /path/to/your/directory  
mkdir MyFolder  
</code></pre>
<p>You can also create nested folders by using the <code>-p</code> option:</p>
<pre><code class="language-bash">mkdir -p parent_folder/child_folder  
</code></pre>
<p>This will create both the parent and child folders if they do not already exist.</p>
<h3>1. Using <code>touch</code></h3>
<p>The <code>touch</code> command is the simplest way to create an empty file:</p>
<pre><code class="language-bash">touch filename.txt  
</code></pre>
<p>This creates an empty file named <code>filename.txt</code>.</p>
<h3>2. Using <code>echo</code></h3>
<p>You can create a file and add some text to it with the <code>echo</code> command:</p>
<pre><code class="language-bash">echo "Hello, World!" > filename.txt  
</code></pre>
<p>This creates a file named <code>filename.txt</code> containing the text "Hello, World!".</p>
<h3>3. Using <code>cat</code></h3>
<p>You can also create a file using the <code>cat</code> command:</p>
<pre><code class="language-bash">cat > filename.txt  
</code></pre>
<p>After running this command, you can type your text. Press <code>Ctrl + D</code> to save and exit.</p>
<h3>4. Using <code>nano</code> or another text editor</h3>
<p>You can create and edit a file using a text editor like <code>nano</code>:</p>
<pre><code class="language-bash">nano filename.txt  
</code></pre>
<p>This opens the <code>nano</code> editor. After typing your content, press <code>Ctrl + X</code>, then <code>Y</code>, and <code>Enter</code> to save.</p>
<h3>5. Using <code>printf</code></h3>
<p>For more complex file creation with formatting, you can use <code>printf</code>:</p>
<pre><code class="language-bash">printf "Line 1\nLine 2\n" > filename.txt  
</code></pre>
<h3>1. Delete a File</h3>
<p>To delete a single file, use the <code>rm</code> command:</p>
<pre><code class="language-bash">rm filename.txt  
</code></pre>
<h3>2. Delete a Folder</h3>
<p>To delete an empty folder, use the <code>rmdir</code> command:</p>
<pre><code class="language-bash">rmdir folder_name  
</code></pre>
<h3>3. Delete a Folder with Files Inside</h3>
<p>To delete a folder and all its contents (including files and subfolders), use the <code>rm</code> command with the <code>-r</code> (recursive) option:</p>
<pre><code class="language-bash">rm -r folder_name  
</code></pre>
<h3>4. Force Delete (Optional)</h3>
<p>If you want to delete without being prompted for confirmation, you can add the <code>-f</code> (force) option:</p>
<pre><code class="language-bash">rm -rf folder_name  
</code></pre>
<h3>Important Note</h3>
<p>Be very careful when using the <code>rm -rf</code> command, as it will permanently delete files and folders without any warning. Always double-check the folder or file name before executing the command.</p>
<p>You can run both commands in a single command line using <code>&#x26;&#x26;</code> or <code>&#x26;</code>, depending on your needs.</p>
<h3>Using <code>&#x26;&#x26;</code></h3>
<p>This will run the second command only if the first command succeeds:</p>
<pre><code class="language-bash">tsc runner.ts &#x26;&#x26; bun runner.js
</code></pre>
<h3>Using <code>&#x26;</code></h3>
<p>This will run both commands concurrently, without waiting for the first to finish:</p>
<pre><code class="language-bash">tsc runner.ts &#x26; bun runner.js
</code></pre>
<p>Choose the method that best suits your use case!</p>
</div></article><article id="/Users/jeevas/Documents/Jeeva/CS Infinity/CS/CS doubt.md" class="bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6"><h3 class="text-xl font-semibold mb-4 text-gray-900 dark:text-white">CS doubt</h3><div class="prose dark:prose-invert prose-sm max-w-none"><p>in hashmap , when collosion happen , it is stored as linked list..</p>
<p>but how this more values to single key makes its usable ?</p>
</div></article><article id="/Users/jeevas/Documents/Jeeva/CS Infinity/CS/Files running.md" class="bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6"><h3 class="text-xl font-semibold mb-4 text-gray-900 dark:text-white">Files running</h3><div class="prose dark:prose-invert prose-sm max-w-none"><p>python file running</p>
<p>python3 filename.py</p>
<p>ts file running</p>
<p>tsc runner.ts &#x26; node runner.js</p>
<p>rs file running</p>
<p>rustc runner.rs &#x26;&#x26; ./runner</p>
</div></article></div></div></div></main></div></div><script src="/_next/static/chunks/webpack-d6abbf1fcfdef890.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"3:\"$Sreact.fragment\"\n4:I[3379,[\"177\",\"static/chunks/app/layout-1843c2dad8a8caeb.js\"],\"default\"]\n5:I[5244,[],\"\"]\n6:I[3866,[],\"\"]\n8:I[6213,[],\"OutletBoundary\"]\na:I[6213,[],\"MetadataBoundary\"]\nc:I[6213,[],\"ViewportBoundary\"]\ne:I[4835,[],\"\"]\n1:HL[\"/_next/static/media/a34f9d1faa5f3315-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/87b0a9fc77e88b3d.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"VQtM1mwsxRepQFu19jaIP\",\"p\":\"\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$3\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/87b0a9fc77e88b3d.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"h-full\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_d65c78 h-full bg-gray-50 dark:bg-gray-900\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-full\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"bg-white dark:bg-gray-800 shadow-sm\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-7xl px-4 sm:px-6 lg:px-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex h-16 justify-between\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-shrink-0 items-center\",\"children\":[\"$\",\"h1\",null,{\"className\":\"text-xl font-bold text-gray-900 dark:text-white\",\"children\":\"CS Infinity\"}]}]}],[\"$\",\"div\",null,{\"className\":\"flex items-center\",\"children\":[\"$\",\"$L4\",null,{}]}]]}]}]}],[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[]}]]}]}]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$3\",\"c\",{\"children\":[\"$L7\",null,[\"$\",\"$L8\",null,{\"children\":\"$L9\"}]]}],{},null]},null],[\"$\",\"$3\",\"h\",{\"children\":[null,[\"$\",\"$3\",\"h7VXuuVu0u14v84p-dAKH\",{\"children\":[[\"$\",\"$La\",null,{\"children\":\"$Lb\"}],[\"$\",\"$Lc\",null,{\"children\":\"$Ld\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\"}]]}]]}]]],\"m\":\"$undefined\",\"G\":[\"$e\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"f:I[4839,[\"839\",\"static/chunks/839-f703ec834851f667.js\",\"974\",\"static/chunks/app/page-b31d2b1bb577579f.js\"],\"\"]\n10:Tade,"])</script><script>self.__next_f.push([1,"\u003cp\u003e![[BigOGraph.png]]\u003c/p\u003e\n\u003cp\u003eBig O :\u003c/p\u003e\n\u003cp\u003ehttps://www.bigocheatsheet.com/\u003c/p\u003e\n\u003cp\u003ehttps://bigocheatsheet.io/\u003c/p\u003e\n\u003ch3\u003eUnderstanding Big O Notation\u003c/h3\u003e\n\u003cp\u003eBig O notation is a mathematical representation that describes the efficiency of an algorithm in terms of time complexity (how fast it runs) and space complexity (how much memory it uses). It provides a way to evaluate how the performance of an algorithm changes as the size of the input, denoted by ( n ), increases.\u003c/p\u003e\n\u003ch4\u003eKey Points of Big O Notation\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eDefinition\u003c/strong\u003e: Big O expresses the upper bound of an algorithm’s running time or space requirement, allowing us to compare efficiencies.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVariables\u003c/strong\u003e: The variable ( n ) represents the number of inputs. For example, if you have an array of 5 elements, ( n = 5 ).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGrowth Rates\u003c/strong\u003e: Algorithms with lower growth rates (e.g., ( O(1) ), ( O(\\log n) )) are generally more efficient than those with higher growth rates (e.g., ( O(n) ), ( O(n^2) )).\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4\u003eCommon Big O Functions (Best to Worst)\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e( O(1) ): Constant time\u003c/li\u003e\n\u003cli\u003e( O(\\log n) ): Logarithmic time\u003c/li\u003e\n\u003cli\u003e( O(n) ): Linear time\u003c/li\u003e\n\u003cli\u003e( O(n \\log n) ): Linearithmic time\u003c/li\u003e\n\u003cli\u003e( O(n^2) ): Quadratic time\u003c/li\u003e\n\u003cli\u003e( O(2^n) ): Exponential time\u003c/li\u003e\n\u003cli\u003e( O(n!) ): Factorial time\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eExample: Comparing Algorithms\u003c/h3\u003e\n\u003cp\u003eLet’s illustrate why Big O notation is important with an example involving two algorithms:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAlgorithm A\u003c/strong\u003e: ( O(\\log n) )\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAlgorithm B\u003c/strong\u003e: ( O(n) )\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eScenario 1: Analyzing 10 Elements\u003c/h4\u003e\n\u003cp\u003eFor ( n = 10 ):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e( O(\\log(10)) ) ≈ 3.3 milliseconds\u003c/li\u003e\n\u003cli\u003e( O(10) ) = 10 milliseconds\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWith 10 elements, the difference in speed is noticeable but might not matter significantly in practice.\u003c/p\u003e\n\u003ch4\u003eScenario 2: Analyzing 10 Million Elements\u003c/h4\u003e\n\u003cp\u003eNow consider ( n = 10,000,000 ):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e( O(\\log(10,000,000)) ) ≈ 23.3 milliseconds\u003c/li\u003e\n\u003cli\u003e( O(10,000,000) ) = 10,000,000 milliseconds (or about 2 hours and 47 minutes)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn this scenario, the performance gap becomes critical. A delay of 2 hours for a search engine would be unacceptable.\u003c/p\u003e\n\u003ch3\u003eConclusion\u003c/h3\u003e\n\u003cp\u003eUnderstanding Big O notation helps you evaluate algorithms' performance and make informed decisions when selecting the right algorithm for your project. As seen, even a small difference in complexity can lead to vastly different performance outcomes with larger datasets.\u003c/p\u003e\n\u003cp\u003eIf you're interested in diving deeper, consider exploring resources that detail the complexities of various data structures and algorithms. This foundational knowledge is invaluable for software engineering and algorithm design!\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"11:Tdbe,"])</script><script>self.__next_f.push([1,"\u003ch2\u003eGreedy Algorithms: An Overview\u003c/h2\u003e\n\u003cp\u003eGreedy algorithms are designed to make the most favorable choice at each step in order to find a solution. This approach can be efficient for specific problems but may not always yield the optimal solution. Let’s explore when to use greedy algorithms, along with an example of their strengths and weaknesses.\u003c/p\u003e\n\u003ch4\u003eKey Characteristics of Greedy Algorithms\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eLocal Optimality\u003c/strong\u003e: At each decision point, the algorithm makes the best local choice without considering the broader consequences.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEfficiency\u003c/strong\u003e: Greedy algorithms typically have lower time complexity since they don’t evaluate every possible outcome.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNot Always Optimal\u003c/strong\u003e: While they can be efficient, greedy algorithms do not guarantee an optimal solution for all problems.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eWhen Not to Use Greedy Algorithms\u003c/h3\u003e\n\u003cp\u003eGreedy algorithms are ineffective in scenarios where making a locally optimal choice does not lead to a globally optimal solution. For example, consider a pathfinding problem where each decision incurs a cost:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eExample\u003c/strong\u003e: Imagine you have a set of paths with different costs:\n\u003cul\u003e\n\u003cli\u003ePath A: $7\u003c/li\u003e\n\u003cli\u003ePath B: $8\u003c/li\u003e\n\u003cli\u003ePath C: $9\u003c/li\u003e\n\u003cli\u003ePath D: $10\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf you use a greedy algorithm, it might choose Path A ($7) first, then Path C ($9), resulting in a total cost of $16. However, the optimal path might only cost $3 by taking a different route entirely.\u003c/p\u003e\n\u003ch3\u003eWhen to Use Greedy Algorithms\u003c/h3\u003e\n\u003cp\u003eGreedy algorithms are suitable for problems where:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAn approximate solution is acceptable.\u003c/li\u003e\n\u003cli\u003eThe problem exhibits optimal substructure, meaning the optimal solution to a problem can be constructed from optimal solutions of its subproblems.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eFamous Example: The Traveling Salesman Problem (TSP)\u003c/h4\u003e\n\u003cp\u003eThe TSP asks for the shortest possible route that visits each city exactly once and returns to the starting point. Given the factorial growth of potential routes, the total number of paths becomes infeasible to calculate for larger datasets:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFor 5 cities: ( (n-1)!/2 = 12 ) routes.\u003c/li\u003e\n\u003cli\u003eFor 10 cities: ( 181,440 ) routes.\u003c/li\u003e\n\u003cli\u003eFor 50 cities: ( 304140932017133780436126081660647688443776415689605120000000000 ) routes.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eGiven such exponential growth, finding an optimal solution using brute force is impractical. Here’s where a greedy approach can be beneficial:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eStarting Point\u003c/strong\u003e: Choose an arbitrary starting city.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNext City\u003c/strong\u003e: Always select the nearest unvisited city.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCompletion\u003c/strong\u003e: Repeat until all cities are visited, then return to the starting city.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eWhile this approach doesn’t guarantee the optimal route, it provides a practical solution that is significantly faster than evaluating all possible paths.\u003c/p\u003e\n\u003ch3\u003eSummary\u003c/h3\u003e\n\u003cp\u003eGreedy algorithms excel in scenarios where:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAn exact optimal solution is infeasible due to the problem’s complexity.\u003c/li\u003e\n\u003cli\u003eA reasonable approximation is acceptable.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThey are best applied to problems that allow for a step-by-step decision-making process leading to a satisfactory solution. Understanding when and how to implement these algorithms can enhance problem-solving efficiency in various computational tasks. If you have more questions or want further clarification on specific examples, feel free to ask!\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"12:T24e8,"])</script><script>self.__next_f.push([1,"\u003ch2\u003eBinary Search\u003c/h2\u003e\n\u003cp\u003eBinary search is an efficient algorithm for finding the position of a specific element in a \u003cstrong\u003esorted\u003c/strong\u003e list. Let’s illustrate this with a guessing game example:\u003c/p\u003e\n\u003cp\u003eImagine your friend chooses a number between \u003cstrong\u003e1 and 100\u003c/strong\u003e, and your task is to guess it.\u003c/p\u003e\n\u003ch4\u003eLinear Search\u003c/h4\u003e\n\u003cp\u003eOne approach is \u003cstrong\u003elinear search\u003c/strong\u003e, where you start at \u003cstrong\u003e1\u003c/strong\u003e and guess each number in sequence. If the correct number is \u003cstrong\u003e100\u003c/strong\u003e, you’d need \u003cstrong\u003e100 guesses\u003c/strong\u003e—which is inefficient, especially with larger ranges (like \u003cstrong\u003e1 to 10,000\u003c/strong\u003e). This method has a time complexity of \u003cstrong\u003eO(n)\u003c/strong\u003e, meaning the number of guesses grows linearly with the size of the list.\u003c/p\u003e\n\u003ch4\u003eBinary Search\u003c/h4\u003e\n\u003cp\u003eNow, let’s consider \u003cstrong\u003ebinary search\u003c/strong\u003e. Instead of starting at \u003cstrong\u003e1\u003c/strong\u003e, you begin by guessing the \u003cstrong\u003emiddle\u003c/strong\u003e of the range, which is \u003cstrong\u003e50\u003c/strong\u003e. Your friend then tells you if the number is higher or lower. Based on that feedback, you can eliminate half of the remaining possibilities with each guess.\u003c/p\u003e\n\u003cp\u003eFor instance:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eGuess \u003cstrong\u003e50\u003c/strong\u003e: If the number is higher, you now consider \u003cstrong\u003e51 to 100\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eGuess the new middle (let's say \u003cstrong\u003e75\u003c/strong\u003e): Continue narrowing down the range based on feedback.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThis method effectively halves the number of options with each guess, leading to a time complexity of \u003cstrong\u003eO(log n)\u003c/strong\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-pseudo\"\u003eFUNCTION binarySearch(array, target):\n    low = 0\n    high = length(array) - 1\n\n    WHILE low \u0026#x3C;= high:\n        mid = (low + high) // 2  // Integer division\n\n        IF array[mid] == target:\n            RETURN mid  // Target found\n        ELSE IF array[mid] \u0026#x3C; target:\n            low = mid + 1  // Search in the right half\n        ELSE:\n            high = mid - 1  // Search in the left half\n\n    RETURN -1  // Target not found\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003eWorst-Case Comparison\u003c/h4\u003e\n\u003cp\u003eTo see how efficient this is, let’s look at the worst-case scenario:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFor linear search in the range \u003cstrong\u003e1 to 10,000\u003c/strong\u003e, you might need \u003cstrong\u003e10,000 guesses\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eFor binary search, using \u003cstrong\u003eO(log n)\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003eCalculate ( \\log_2(10,000) ), which is approximately \u003cstrong\u003e13.3\u003c/strong\u003e. Thus, you’d need \u003cstrong\u003e14 guesses\u003c/strong\u003e in the worst case.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eConclusion\u003c/h4\u003e\n\u003cp\u003eBinary search is a powerful tool, particularly when dealing with sorted lists. Its efficiency makes it significantly faster than linear search for large datasets. Just remember: binary search only works on sorted data. If you find yourself needing to search through a sorted list, binary search is an excellent approach to consider.\u003c/p\u003e\n\u003ch2\u003eDepth-First Search (DFS)\u003c/h2\u003e\n\u003cp\u003eDepth-First Search (DFS) is a traversal algorithm used to explore nodes and edges in a graph or tree structure. The key idea behind DFS is to start at the \u003cstrong\u003eroot node\u003c/strong\u003e and explore as far down one branch as possible before backtracking. This approach effectively utilizes a technique called \u003cstrong\u003ebacktracking\u003c/strong\u003e.\u003c/p\u003e\n\u003ch4\u003eHow DFS Works\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eInitialization\u003c/strong\u003e: Before starting DFS, create a \u003cstrong\u003evisited array\u003c/strong\u003e to keep track of nodes you’ve already explored.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eTraversal\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBegin at the \u003cstrong\u003eroot node\u003c/strong\u003e and add it to the visited array.\u003c/li\u003e\n\u003cli\u003eMove to the first child node and add it to the visited array.\u003c/li\u003e\n\u003cli\u003eContinue down this branch, visiting nodes and adding them to the visited array until you reach a node with no unvisited children.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eBacktracking\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eOnce you hit a dead end, backtrack to the previous node and check for any unvisited children.\u003c/li\u003e\n\u003cli\u003eIf there are unvisited nodes, proceed down that branch and repeat the process.\u003c/li\u003e\n\u003cli\u003eIf not, backtrack further up until all nodes have been visited.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThis process continues until the entire graph has been explored.\u003c/p\u003e\n\u003ch4\u003eVisual Example\u003c/h4\u003e\n\u003cp\u003eImagine navigating a maze: you start at the entrance and explore each path to its end. If you encounter a wall, you backtrack to the last junction and try another path. This method of exploration allows you to efficiently search through complex structures.\u003c/p\u003e\n\u003cp\u003eRecursive DFS Pseudocode\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-pseudo\"\u003eFUNCTION DFS(node, visited):\n    IF node IS NULL:\n        RETURN\n\n    // Mark the node as visited\n    visited.add(node)\n\n    // Process the current node (e.g., print it)\n    PRINT(node)\n\n    // Recur for each unvisited adjacent node\n    FOR each neighbor in node.adjacent:\n        IF neighbor NOT IN visited:\n            DFS(neighbor, visited)\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIterative DFS Pseudocode\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-pseudo\"\u003eFUNCTION iterativeDFS(root):\n    visited = empty set\n    stack = empty stack\n\n    stack.push(root)\n\n    WHILE stack is not empty:\n        node = stack.pop()\n\n        IF node NOT IN visited:\n            visited.add(node)\n\n            // Process the current node (e.g., print it)\n            PRINT(node)\n\n            // Add all unvisited neighbors to the stack\n            FOR each neighbor in node.adjacent:\n                IF neighbor NOT IN visited:\n                    stack.push(neighbor)\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003eTime Complexity\u003c/h4\u003e\n\u003cp\u003eThe time complexity of DFS is expressed as \u003cstrong\u003eO(V + E)\u003c/strong\u003e, where:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eV\u003c/strong\u003e is the total number of \u003cstrong\u003evertices\u003c/strong\u003e (or nodes).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eE\u003c/strong\u003e is the total number of \u003cstrong\u003eedges\u003c/strong\u003e (or branches).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis complexity arises because, in the worst case, you may need to visit every node and edge.\u003c/p\u003e\n\u003ch4\u003eReal-World Applications\u003c/h4\u003e\n\u003cp\u003eDFS is particularly useful in scenarios like:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eMaze solving\u003c/strong\u003e: Finding a path through a maze by exploring all possible routes.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePuzzle solving\u003c/strong\u003e: Games like Sudoku, where exploring different configurations is necessary.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGraph algorithms\u003c/strong\u003e: Such as topological sorting and finding connected components.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNow that we’ve covered DFS, let’s move on to its counterpart: \u003cstrong\u003eBreadth-First Search (BFS)\u003c/strong\u003e.\u003c/p\u003e\n\u003ch2\u003eBreadth-First Search (BFS)\u003c/h2\u003e\n\u003cp\u003eBreadth-First Search (BFS) is an algorithm used to explore nodes and edges in a graph or tree structure. Unlike Depth-First Search (DFS), BFS explores all the nodes at the current level before moving on to the next level. This level-by-level approach makes it intuitive and easy to understand.\u003c/p\u003e\n\u003ch4\u003eHow BFS Works\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eInitialization\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCreate a \u003cstrong\u003evisited array\u003c/strong\u003e to track which nodes have been explored.\u003c/li\u003e\n\u003cli\u003eCreate a \u003cstrong\u003equeue\u003c/strong\u003e to hold the nodes that need to be explored.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eTraversal\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eStart at the \u003cstrong\u003eroot node\u003c/strong\u003e, mark it as visited, and add it to the queue.\u003c/li\u003e\n\u003cli\u003eWhile the queue is not empty:\n\u003cul\u003e\n\u003cli\u003eDequeue the front node.\u003c/li\u003e\n\u003cli\u003eProcess that node (e.g., print it or store it).\u003c/li\u003e\n\u003cli\u003eEnqueue all its unvisited neighbors, marking them as visited as you go.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eLevel-by-Level Exploration\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eContinue this process until all reachable nodes have been visited, ensuring that you explore each level fully before proceeding to the next.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4\u003eVisual Example\u003c/h4\u003e\n\u003cp\u003eThink of BFS like exploring a building floor by floor. You check every room on the first floor before moving to the second floor. This systematic approach ensures that you see all possible connections at each level.\u003c/p\u003e\n\u003ch4\u003eReal-World Applications\u003c/h4\u003e\n\u003cp\u003eBFS is commonly used in scenarios such as:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eChess algorithms\u003c/strong\u003e: To evaluate possible moves by exploring all possible next moves and their subsequent options.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSocial networking\u003c/strong\u003e: Finding the shortest path between users.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWeb crawling\u003c/strong\u003e: To explore web pages level by level.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eTime Complexity\u003c/h4\u003e\n\u003cp\u003eThe time complexity of BFS is also \u003cstrong\u003eO(V + E)\u003c/strong\u003e, where:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eV\u003c/strong\u003e is the total number of vertices (nodes).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eE\u003c/strong\u003e is the total number of edges (connections).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003ePseudocode for Breadth-First Search\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-plaintext\"\u003eFUNCTION BFS(root):\n    visited = empty set\n    queue = empty queue\n\n    // Start with the root node\n    visited.add(root)\n    queue.enqueue(root)\n\n    WHILE queue is not empty:\n        node = queue.dequeue()\n\n        // Process the current node (e.g., print it)\n        PRINT(node)\n\n        // Enqueue all unvisited neighbors\n        FOR each neighbor in node.adjacent:\n            IF neighbor NOT IN visited:\n                visited.add(neighbor)\n                queue.enqueue(neighbor)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eSummary\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBFS\u003c/strong\u003e efficiently explores nodes level by level, ensuring that all neighbors are examined before moving deeper.\u003c/li\u003e\n\u003cli\u003eThe algorithm is particularly useful for problems requiring the shortest path or level-based exploration.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf you have any further questions or need more examples, feel free to ask!\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"13:T3266,"])</script><script>self.__next_f.push([1,"\u003ch2\u003eInsertion Sort Explained\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eInsertion Sort\u003c/strong\u003e is a straightforward and intuitive sorting algorithm. It builds a sorted array (or list) one element at a time by repeatedly taking an unsorted element and inserting it into its correct position within the sorted portion of the array.\u003c/p\u003e\n\u003ch4\u003eHow Insertion Sort Works\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eStart with the first element\u003c/strong\u003e: Consider the first element as a sorted portion.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eCompare and Insert\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTake the next element in the unsorted portion.\u003c/li\u003e\n\u003cli\u003eCompare it with elements in the sorted portion, moving from right to left.\u003c/li\u003e\n\u003cli\u003eIf the current element is smaller than the compared element, shift the compared element to the right.\u003c/li\u003e\n\u003cli\u003eInsert the current element in its correct position once you find the right spot.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eRepeat\u003c/strong\u003e: Continue this process for all elements in the list until the entire array is sorted.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4\u003eExample\u003c/h4\u003e\n\u003cp\u003eLet’s say we have the following list: \u003ccode\u003e[5, 2, 9, 1, 5, 6]\u003c/code\u003e.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eStart with the first element (5). It’s already sorted.\u003c/li\u003e\n\u003cli\u003eCompare 2 with 5; since 2 \u0026#x3C; 5, swap them. The list is now \u003ccode\u003e[2, 5, 9, 1, 5, 6]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eCompare 9 with 5; since 9 \u003e 5, leave it.\u003c/li\u003e\n\u003cli\u003eCompare 1 with 9; since 1 \u0026#x3C; 9, shift 9 to the right. Now compare with 5; shift 5 to the right. Insert 1. The list is now \u003ccode\u003e[1, 2, 5, 9, 5, 6]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eContinue this process until the list is fully sorted.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eTime Complexity\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBest Case\u003c/strong\u003e: \u003cstrong\u003eO(n)\u003c/strong\u003e, which occurs when the list is already sorted. The algorithm makes a single pass through the list.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWorst Case\u003c/strong\u003e: \u003cstrong\u003eO(n²)\u003c/strong\u003e, which occurs when the list is in reverse order. Each element has to be compared with every other element.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAverage Case\u003c/strong\u003e: \u003cstrong\u003eO(n²)\u003c/strong\u003e, typical for randomly ordered lists.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eWhen to Use Insertion Sort\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eMostly Sorted Lists\u003c/strong\u003e: Insertion sort performs well when the list is nearly sorted, as it can achieve linear time complexity.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSmall Lists\u003c/strong\u003e: Due to its simplicity and low overhead, it’s efficient for small datasets.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStability\u003c/strong\u003e: Insertion sort is a stable sort, meaning that it preserves the relative order of equal elements.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003ePseudocode for Insertion Sort\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-plaintext\"\u003eFUNCTION insertionSort(array):\n    FOR i FROM 1 TO length(array) - 1:\n        key = array[i]\n        j = i - 1\n\n        // Move elements of array[0..i-1] that are greater than key\n        WHILE j \u003e= 0 AND array[j] \u003e key:\n            array[j + 1] = array[j]\n            j = j - 1\n\n        array[j + 1] = key  // Insert key into its correct position\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eSummary\u003c/h3\u003e\n\u003cp\u003eInsertion Sort is an effective algorithm for small or nearly sorted datasets. While it may not be suitable for large lists due to its O(n²) worst-case runtime, it is easy to implement and understand, making it a good choice for certain scenarios. If you have more questions or need further examples, feel free to ask!\u003c/p\u003e\n\u003ch3\u003eInsertion Sort vs. Merge Sort\u003c/h3\u003e\n\u003ch4\u003eInsertion Sort Overview\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003eInsertion Sort\u003c/strong\u003e is a simple sorting algorithm that builds a sorted array one element at a time. Here’s a quick recap of its performance:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBest Case\u003c/strong\u003e: \u003cstrong\u003eO(n)\u003c/strong\u003e when the array is already sorted, as it only requires a single pass through the elements.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWorst Case\u003c/strong\u003e: \u003cstrong\u003eO(n²)\u003c/strong\u003e when the array is in reverse order, necessitating comparisons with every other element.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUse Cases\u003c/strong\u003e: Best for small or nearly sorted lists due to its simplicity and efficiency in those scenarios.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eMerge Sort Overview\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eMerge Sort\u003c/strong\u003e is a more advanced sorting algorithm that uses the \u003cstrong\u003edivide-and-conquer\u003c/strong\u003e strategy. It efficiently handles larger and more complex datasets. Here’s how it works:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eDivide\u003c/strong\u003e: Split the array into two halves. This process continues recursively until each subarray contains a single element.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eConquer\u003c/strong\u003e: Merge the sorted subarrays back together. During this process, compare the elements from each half and sort them as you combine them.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eCombine\u003c/strong\u003e: The merging process continues until the entire array is reconstructed in sorted order.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4\u003eVisualization of Merge Sort\u003c/h4\u003e\n\u003cp\u003eImagine you have an array \u003ccode\u003e[38, 27, 43, 3, 9, 82, 10]\u003c/code\u003e:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eSplitting\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFirst, split into \u003ccode\u003e[38, 27, 43]\u003c/code\u003e and \u003ccode\u003e[3, 9, 82, 10]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eSplit further until you reach single elements: \u003ccode\u003e[38]\u003c/code\u003e, \u003ccode\u003e[27]\u003c/code\u003e, \u003ccode\u003e[43]\u003c/code\u003e, \u003ccode\u003e[3]\u003c/code\u003e, \u003ccode\u003e[9]\u003c/code\u003e, \u003ccode\u003e[82]\u003c/code\u003e, \u003ccode\u003e[10]\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eMerging\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMerge pairs: \u003ccode\u003e[27, 38]\u003c/code\u003e, \u003ccode\u003e[3, 9, 10, 82]\u003c/code\u003e, \u003ccode\u003e[43]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eContinue merging while sorting: \u003ccode\u003e[27, 38, 43]\u003c/code\u003e and \u003ccode\u003e[3, 9, 10, 82]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eFinally, combine to get the fully sorted array: \u003ccode\u003e[3, 9, 10, 27, 38, 43, 82]\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4\u003eTime Complexity\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eMerge Sort\u003c/strong\u003e: Both best and worst-case time complexity is \u003cstrong\u003eO(n log n)\u003c/strong\u003e. This efficiency makes it suitable for large datasets.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eInsertion Sort vs. Merge Sort\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003eFor small or mostly sorted lists, Insertion Sort is more efficient (O(n)).\u003c/li\u003e\n\u003cli\u003eFor larger, unsorted lists, Merge Sort is preferable due to its O(n log n) runtime, which remains consistent regardless of initial order.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eSummary\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eInsertion Sort\u003c/strong\u003e: Effective for small or nearly sorted lists with a best-case of O(n) but poor performance on larger datasets (O(n²)).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMerge Sort\u003c/strong\u003e: Ideal for larger or more unordered lists, consistently performing at O(n log n), leveraging the power of recursion and divide-and-conquer.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eUnderstanding these algorithms allows you to choose the right one based on the size and initial order of the dataset you're working with. If you have any further questions or need additional examples, feel free to ask!\u003c/p\u003e\n\u003cp\u003eHere’s the pseudocode for \u003cstrong\u003eMerge Sort\u003c/strong\u003e:\u003c/p\u003e\n\u003ch3\u003eMerge Sort Pseudocode\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-plaintext\"\u003eFUNCTION mergeSort(array):\n    IF length(array) \u0026#x3C;= 1:\n        RETURN array  // Base case: an array of zero or one element is already sorted\n\n    // Divide the array into two halves\n    mid = length(array) // 2\n    left = mergeSort(array[0:mid])    // Recursively sort the left half\n    right = mergeSort(array[mid:end])  // Recursively sort the right half\n\n    // Merge the sorted halves\n    RETURN merge(left, right)\n\nFUNCTION merge(left, right):\n    result = empty array\n    i = 0  // Pointer for left array\n    j = 0  // Pointer for right array\n\n    // Merge elements from both arrays in sorted order\n    WHILE i \u0026#x3C; length(left) AND j \u0026#x3C; length(right):\n        IF left[i] \u0026#x3C;= right[j]:\n            result.append(left[i])\n            i = i + 1\n        ELSE:\n            result.append(right[j])\n            j = j + 1\n\n    // Append any remaining elements from left array\n    WHILE i \u0026#x3C; length(left):\n        result.append(left[i])\n        i = i + 1\n\n    // Append any remaining elements from right array\n    WHILE j \u0026#x3C; length(right):\n        result.append(right[j])\n        j = j + 1\n\n    RETURN result  // Return the merged and sorted array\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eExplanation\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eBase Case\u003c/strong\u003e: If the array has one or no elements, it’s already sorted.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDivide\u003c/strong\u003e: The array is split into two halves.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eConquer\u003c/strong\u003e: Each half is sorted recursively using \u003ccode\u003emergeSort\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMerge\u003c/strong\u003e: The sorted halves are combined into a single sorted array using the \u003ccode\u003emerge\u003c/code\u003e function.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThis pseudocode clearly outlines how Merge Sort operates, utilizing recursion and the merging process to achieve efficient sorting. If you have more questions or need further details, just let me know!\u003c/p\u003e\n\u003ch2\u003eQuick Sort Overview\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eQuick Sort\u003c/strong\u003e is a powerful and efficient sorting algorithm that follows the \u003cstrong\u003edivide-and-conquer\u003c/strong\u003e strategy. It's known for its speed in practical scenarios, making it one of the most commonly used sorting algorithms, despite its potential for poor performance in specific cases.\u003c/p\u003e\n\u003ch4\u003eHow Quick Sort Works\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eChoose a Pivot\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSelect a pivot element from the array. The ideal choice is a value close to the median, as this helps to balance the partitions.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003ePartitioning\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRearrange the array so that elements less than the pivot come before it and elements greater than the pivot come after it. This process is called partitioning.\u003c/li\u003e\n\u003cli\u003eThe pivot is then placed in its correct position in the sorted array.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eRecursion\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRecursively apply the above steps to the sub-arrays formed by partitioning (the left sub-array and the right sub-array).\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eBase Case\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe recursion ends when the sub-arrays have one or no elements, as they are already sorted.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4\u003eVisualization Example\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003eStart with the array: \u003ccode\u003e[10, 7, 8, 9, 1, 5]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eSelect a pivot (e.g., \u003ccode\u003e8\u003c/code\u003e). Move it to the end of the list: \u003ccode\u003e[10, 7, 9, 1, 5, 8]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eSet pointers at the leftmost and rightmost ends:\n\u003cul\u003e\n\u003cli\u003eCompare elements and swap as needed to ensure all elements left of the pivot are less than it, and all elements right are greater.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eOnce the pointers cross, place the pivot in its correct position. The array might look like: \u003ccode\u003e[7, 5, 1, 8, 10, 9]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eRecursively apply the same steps to the sub-arrays \u003ccode\u003e[7, 5, 1]\u003c/code\u003e and \u003ccode\u003e[10, 9]\u003c/code\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4\u003eTime Complexity\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBest Case\u003c/strong\u003e: \u003cstrong\u003eO(n log n)\u003c/strong\u003e when the pivot divides the array into two equal halves.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAverage Case\u003c/strong\u003e: \u003cstrong\u003eO(n log n)\u003c/strong\u003e; this is where Quick Sort shines.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWorst Case\u003c/strong\u003e: \u003cstrong\u003eO(n²)\u003c/strong\u003e occurs when the smallest or largest element is consistently chosen as the pivot (e.g., already sorted arrays).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eSpace Complexity\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eQuick Sort\u003c/strong\u003e: \u003cstrong\u003eO(log n)\u003c/strong\u003e due to the recursive stack space.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMerge Sort\u003c/strong\u003e: \u003cstrong\u003eO(n)\u003c/strong\u003e due to the need for temporary arrays during the merge process.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eWhy Use Quick Sort?\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eSpeed\u003c/strong\u003e: On average, Quick Sort tends to be faster than both Insertion Sort and Merge Sort due to its efficient in-place partitioning.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMemory Efficiency\u003c/strong\u003e: Uses less memory than Merge Sort.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePerformance Tuning\u003c/strong\u003e: With careful implementation (like choosing good pivots), it can avoid worst-case scenarios.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003ePseudocode for Quick Sort\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-plaintext\"\u003eFUNCTION quickSort(array, low, high):\n    IF low \u0026#x3C; high:\n        // Partition the array and get the pivot index\n        pivotIndex = partition(array, low, high)\n\n        // Recursively sort elements before and after the partition\n        quickSort(array, low, pivotIndex - 1)\n        quickSort(array, pivotIndex + 1, high)\n\nFUNCTION partition(array, low, high):\n    pivot = array[high]  // Choose the last element as the pivot\n    i = low - 1          // Pointer for the smaller element\n\n    FOR j FROM low TO high - 1:\n        IF array[j] \u0026#x3C;= pivot:\n            i = i + 1\n            swap(array[i], array[j])  // Swap if element is smaller than the pivot\n\n    swap(array[i + 1], array[high])  // Swap the pivot into the correct position\n    RETURN i + 1  // Return the partition index\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eSummary\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eQuick Sort\u003c/strong\u003e is an efficient, recursive, divide-and-conquer algorithm that, when implemented correctly, is typically faster than other sorting algorithms on average.\u003c/li\u003e\n\u003cli\u003eUnderstanding its mechanics and proper implementation is crucial, as even minor mistakes can lead to inefficiencies.\u003c/li\u003e\n\u003cli\u003eIts low space complexity makes it a favorable choice for large datasets.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf you have more questions or need additional explanations, feel free to ask!\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"14:Tfa6,"])</script><script>self.__next_f.push([1,"\u003cp\u003eObject-Relational Mappers (ORMs) are tools that help developers interact with databases using object-oriented programming languages. Here’s a list of some of the most popular ORMs in various programming languages:\u003c/p\u003e\n\u003ch3\u003ePython\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eSQLAlchemy\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA powerful and flexible ORM that provides a full suite of well-known enterprise-level persistence patterns. It supports both high-level ORM capabilities and low-level database interaction.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eDjango ORM\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBuilt into the Django web framework, it allows developers to interact with databases using Python objects and provides a powerful query language.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003ePeewee\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA small and expressive ORM that is easy to use and well-suited for small projects or applications that don’t need the full complexity of SQLAlchemy.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eJavaScript\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eSequelize\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA promise-based ORM for Node.js that supports multiple SQL dialects like PostgreSQL, MySQL, and SQLite. It features migrations, model validation, and associations.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eTypeORM\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAn ORM for TypeScript and JavaScript (ES7, ES6, ES5) that supports Active Record and Data Mapper patterns. It works with various databases and is great for TypeScript projects.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eMongoose\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAn ODM (Object Data Modeling) library for MongoDB and Node.js, providing a schema-based solution to model application data.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eRuby\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eActive Record\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe default ORM for Ruby on Rails, it provides a straightforward way to interact with databases and supports features like migrations, validations, and associations.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eSequel\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA simple, flexible ORM for Ruby that supports multiple databases and offers a powerful query DSL.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003ePHP\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eEloquent\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe ORM included with the Laravel framework. It provides an elegant and expressive syntax for working with databases and includes support for relationships, eager loading, and more.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eDoctrine\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA powerful ORM for PHP that supports complex data models and is used widely in Symfony applications.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eC#\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eEntity Framework\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA popular ORM for .NET applications that supports both Code First and Database First approaches. It provides a rich set of features for querying and updating databases.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eDapper\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA lightweight ORM for .NET that focuses on performance. It’s not as feature-rich as Entity Framework but is very fast and suitable for simple scenarios.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eGo\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eGORM\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAn ORM for Go that provides an easy way to interact with databases and supports associations, hooks, and migrations.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eEnt\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAn ORM for Go that focuses on code generation and type safety, making it easy to work with complex data models.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eConclusion\u003c/h3\u003e\n\u003cp\u003eWhen choosing an ORM, consider the following:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eProject Requirements\u003c/strong\u003e: Some ORMs are better suited for complex applications, while others are lightweight for simpler projects.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDatabase Support\u003c/strong\u003e: Ensure the ORM supports the database system you plan to use.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCommunity and Documentation\u003c/strong\u003e: A strong community and good documentation can make a big difference in development speed and troubleshooting.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eUltimately, the best ORM for your project will depend on your specific needs, the programming language you're using, and the overall architecture of your application.\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"15:Te55,"])</script><script>self.__next_f.push([1,"\u003cp\u003eTerminal linux commands:\nTo create a folder\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003emkdir folder_name  \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf you want to create a folder in a specific directory, navigate to that directory using the \u003ccode\u003ecd\u003c/code\u003e command first:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003ecd /path/to/your/directory  \nmkdir MyFolder  \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can also create nested folders by using the \u003ccode\u003e-p\u003c/code\u003e option:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003emkdir -p parent_folder/child_folder  \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis will create both the parent and child folders if they do not already exist.\u003c/p\u003e\n\u003ch3\u003e1. Using \u003ccode\u003etouch\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eThe \u003ccode\u003etouch\u003c/code\u003e command is the simplest way to create an empty file:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003etouch filename.txt  \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis creates an empty file named \u003ccode\u003efilename.txt\u003c/code\u003e.\u003c/p\u003e\n\u003ch3\u003e2. Using \u003ccode\u003eecho\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eYou can create a file and add some text to it with the \u003ccode\u003eecho\u003c/code\u003e command:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eecho \"Hello, World!\" \u003e filename.txt  \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis creates a file named \u003ccode\u003efilename.txt\u003c/code\u003e containing the text \"Hello, World!\".\u003c/p\u003e\n\u003ch3\u003e3. Using \u003ccode\u003ecat\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eYou can also create a file using the \u003ccode\u003ecat\u003c/code\u003e command:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003ecat \u003e filename.txt  \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAfter running this command, you can type your text. Press \u003ccode\u003eCtrl + D\u003c/code\u003e to save and exit.\u003c/p\u003e\n\u003ch3\u003e4. Using \u003ccode\u003enano\u003c/code\u003e or another text editor\u003c/h3\u003e\n\u003cp\u003eYou can create and edit a file using a text editor like \u003ccode\u003enano\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003enano filename.txt  \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis opens the \u003ccode\u003enano\u003c/code\u003e editor. After typing your content, press \u003ccode\u003eCtrl + X\u003c/code\u003e, then \u003ccode\u003eY\u003c/code\u003e, and \u003ccode\u003eEnter\u003c/code\u003e to save.\u003c/p\u003e\n\u003ch3\u003e5. Using \u003ccode\u003eprintf\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eFor more complex file creation with formatting, you can use \u003ccode\u003eprintf\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eprintf \"Line 1\\nLine 2\\n\" \u003e filename.txt  \n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e1. Delete a File\u003c/h3\u003e\n\u003cp\u003eTo delete a single file, use the \u003ccode\u003erm\u003c/code\u003e command:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003erm filename.txt  \n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e2. Delete a Folder\u003c/h3\u003e\n\u003cp\u003eTo delete an empty folder, use the \u003ccode\u003ermdir\u003c/code\u003e command:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003ermdir folder_name  \n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e3. Delete a Folder with Files Inside\u003c/h3\u003e\n\u003cp\u003eTo delete a folder and all its contents (including files and subfolders), use the \u003ccode\u003erm\u003c/code\u003e command with the \u003ccode\u003e-r\u003c/code\u003e (recursive) option:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003erm -r folder_name  \n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4. Force Delete (Optional)\u003c/h3\u003e\n\u003cp\u003eIf you want to delete without being prompted for confirmation, you can add the \u003ccode\u003e-f\u003c/code\u003e (force) option:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003erm -rf folder_name  \n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eImportant Note\u003c/h3\u003e\n\u003cp\u003eBe very careful when using the \u003ccode\u003erm -rf\u003c/code\u003e command, as it will permanently delete files and folders without any warning. Always double-check the folder or file name before executing the command.\u003c/p\u003e\n\u003cp\u003eYou can run both commands in a single command line using \u003ccode\u003e\u0026#x26;\u0026#x26;\u003c/code\u003e or \u003ccode\u003e\u0026#x26;\u003c/code\u003e, depending on your needs.\u003c/p\u003e\n\u003ch3\u003eUsing \u003ccode\u003e\u0026#x26;\u0026#x26;\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eThis will run the second command only if the first command succeeds:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003etsc runner.ts \u0026#x26;\u0026#x26; bun runner.js\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eUsing \u003ccode\u003e\u0026#x26;\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eThis will run both commands concurrently, without waiting for the first to finish:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003etsc runner.ts \u0026#x26; bun runner.js\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eChoose the method that best suits your use case!\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"div\",null,{\"className\":\"flex h-full\",\"children\":[[\"$\",\"div\",null,{\"className\":\"hidden lg:fixed lg:inset-y-0 lg:flex lg:w-64 lg:flex-col\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex grow flex-col gap-y-5 overflow-y-auto border-r border-gray-200 bg-white px-6 pb-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex h-16 shrink-0 items-center\",\"children\":[\"$\",\"span\",null,{\"className\":\"text-lg font-semibold\",\"children\":\"Categories\"}]}],[\"$\",\"nav\",null,{\"className\":\"flex flex-1 flex-col\",\"children\":[\"$\",\"ul\",null,{\"role\":\"list\",\"className\":\"flex flex-1 flex-col gap-y-7\",\"children\":[[\"$\",\"li\",\"Famous algo\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"text-xs font-semibold leading-6 text-gray-400\",\"children\":\"Famous algo\"}],[\"$\",\"ul\",null,{\"role\":\"list\",\"className\":\"-mx-2 mt-2 space-y-1\",\"children\":[[\"$\",\"li\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/0 Outline.md\",{\"children\":[\"$\",\"$Lf\",null,{\"href\":\"#/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/0 Outline.md\",\"className\":\"text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold\",\"children\":\"0 Outline\"}]}],[\"$\",\"li\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Big O.md\",{\"children\":[\"$\",\"$Lf\",null,{\"href\":\"#/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Big O.md\",\"className\":\"text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold\",\"children\":\"Big O\"}]}],[\"$\",\"li\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Greedy.md\",{\"children\":[\"$\",\"$Lf\",null,{\"href\":\"#/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Greedy.md\",\"className\":\"text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold\",\"children\":\"Greedy\"}]}],[\"$\",\"li\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Search.md\",{\"children\":[\"$\",\"$Lf\",null,{\"href\":\"#/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Search.md\",\"className\":\"text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold\",\"children\":\"Search\"}]}],[\"$\",\"li\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Sort.md\",{\"children\":[\"$\",\"$Lf\",null,{\"href\":\"#/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Sort.md\",\"className\":\"text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold\",\"children\":\"Sort\"}]}]]}]]}],[\"$\",\"li\",\"sorting\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"text-xs font-semibold leading-6 text-gray-400\",\"children\":\"sorting\"}],[\"$\",\"ul\",null,{\"role\":\"list\",\"className\":\"-mx-2 mt-2 space-y-1\",\"children\":[[\"$\",\"li\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/sorting/Sort.md\",{\"children\":[\"$\",\"$Lf\",null,{\"href\":\"#/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/sorting/Sort.md\",\"className\":\"text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold\",\"children\":\"Sort\"}]}]]}]]}],[\"$\",\"li\",\"ORMs\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"text-xs font-semibold leading-6 text-gray-400\",\"children\":\"ORMs\"}],[\"$\",\"ul\",null,{\"role\":\"list\",\"className\":\"-mx-2 mt-2 space-y-1\",\"children\":[[\"$\",\"li\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/CS/Backend/DB/ORMs/Stacks.md\",{\"children\":[\"$\",\"$Lf\",null,{\"href\":\"#/Users/jeevas/Documents/Jeeva/CS Infinity/CS/Backend/DB/ORMs/Stacks.md\",\"className\":\"text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold\",\"children\":\"Stacks\"}]}]]}]]}],[\"$\",\"li\",\"CS\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"text-xs font-semibold leading-6 text-gray-400\",\"children\":\"CS\"}],[\"$\",\"ul\",null,{\"role\":\"list\",\"className\":\"-mx-2 mt-2 space-y-1\",\"children\":[[\"$\",\"li\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/CS/CMD commands.md\",{\"children\":[\"$\",\"$Lf\",null,{\"href\":\"#/Users/jeevas/Documents/Jeeva/CS Infinity/CS/CMD commands.md\",\"className\":\"text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold\",\"children\":\"CMD commands\"}]}],[\"$\",\"li\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/CS/CS doubt.md\",{\"children\":[\"$\",\"$Lf\",null,{\"href\":\"#/Users/jeevas/Documents/Jeeva/CS Infinity/CS/CS doubt.md\",\"className\":\"text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold\",\"children\":\"CS doubt\"}]}],[\"$\",\"li\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/CS/Files running.md\",{\"children\":[\"$\",\"$Lf\",null,{\"href\":\"#/Users/jeevas/Documents/Jeeva/CS Infinity/CS/Files running.md\",\"className\":\"text-gray-700 hover:text-indigo-600 hover:bg-gray-50 group flex gap-x-3 rounded-md p-2 text-sm leading-6 font-semibold\",\"children\":\"Files running\"}]}]]}]]}]]}]}]]}]}],[\"$\",\"main\",null,{\"className\":\"py-10 lg:pl-72\",\"children\":[\"$\",\"div\",null,{\"className\":\"px-4 sm:px-6 lg:px-8\",\"children\":[[\"$\",\"div\",\"Famous algo\",{\"className\":\"mb-12\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-bold mb-6 text-gray-900 dark:text-white\",\"children\":\"Famous algo\"}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-2 gap-6\",\"children\":[[\"$\",\"article\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/0 Outline.md\",{\"id\":\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/0 Outline.md\",\"className\":\"bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold mb-4 text-gray-900 dark:text-white\",\"children\":\"0 Outline\"}],[\"$\",\"div\",null,{\"className\":\"prose dark:prose-invert prose-sm max-w-none\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003cp\u003eNoted\u003c/p\u003e\\n\u003cp\u003e\u003ca href=\\\"https://youtu.be/kp3fCihUXEg?si=lJoiiwBRlFpFtJu3\\\"\u003etop 7 algo\u003c/a\u003e\\n\u003ca href=\\\"https://www.youtube.com/watch?v=4TUgqm2gJkE\\\"\u003ebigO\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003e[[Search]]\\n[[Famous algo/Sort]]\\n[[Greedy]]\u003c/p\u003e\\n\u003cp\u003e[[Big O]]\u003c/p\u003e\\n\"}}]]}],[\"$\",\"article\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Big O.md\",{\"id\":\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Big O.md\",\"className\":\"bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold mb-4 text-gray-900 dark:text-white\",\"children\":\"Big O\"}],[\"$\",\"div\",null,{\"className\":\"prose dark:prose-invert prose-sm max-w-none\",\"dangerouslySetInnerHTML\":{\"__html\":\"$10\"}}]]}],[\"$\",\"article\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Greedy.md\",{\"id\":\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Greedy.md\",\"className\":\"bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold mb-4 text-gray-900 dark:text-white\",\"children\":\"Greedy\"}],[\"$\",\"div\",null,{\"className\":\"prose dark:prose-invert prose-sm max-w-none\",\"dangerouslySetInnerHTML\":{\"__html\":\"$11\"}}]]}],[\"$\",\"article\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Search.md\",{\"id\":\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Search.md\",\"className\":\"bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold mb-4 text-gray-900 dark:text-white\",\"children\":\"Search\"}],[\"$\",\"div\",null,{\"className\":\"prose dark:prose-invert prose-sm max-w-none\",\"dangerouslySetInnerHTML\":{\"__html\":\"$12\"}}]]}],[\"$\",\"article\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Sort.md\",{\"id\":\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/Famous algo/Sort.md\",\"className\":\"bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold mb-4 text-gray-900 dark:text-white\",\"children\":\"Sort\"}],[\"$\",\"div\",null,{\"className\":\"prose dark:prose-invert prose-sm max-w-none\",\"dangerouslySetInnerHTML\":{\"__html\":\"$13\"}}]]}]]}]]}],[\"$\",\"div\",\"sorting\",{\"className\":\"mb-12\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-bold mb-6 text-gray-900 dark:text-white\",\"children\":\"sorting\"}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-2 gap-6\",\"children\":[[\"$\",\"article\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/sorting/Sort.md\",{\"id\":\"/Users/jeevas/Documents/Jeeva/CS Infinity/Algorithms/sorting/Sort.md\",\"className\":\"bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold mb-4 text-gray-900 dark:text-white\",\"children\":\"Sort\"}],[\"$\",\"div\",null,{\"className\":\"prose dark:prose-invert prose-sm max-w-none\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003cp\u003esorting olympics\u003c/p\u003e\\n\u003cp\u003ehttps://www.youtube.com/watch?v=N4JVT3eVBP8\u003c/p\u003e\\n\"}}]]}]]}]]}],[\"$\",\"div\",\"ORMs\",{\"className\":\"mb-12\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-bold mb-6 text-gray-900 dark:text-white\",\"children\":\"ORMs\"}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-2 gap-6\",\"children\":[[\"$\",\"article\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/CS/Backend/DB/ORMs/Stacks.md\",{\"id\":\"/Users/jeevas/Documents/Jeeva/CS Infinity/CS/Backend/DB/ORMs/Stacks.md\",\"className\":\"bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold mb-4 text-gray-900 dark:text-white\",\"children\":\"Stacks\"}],[\"$\",\"div\",null,{\"className\":\"prose dark:prose-invert prose-sm max-w-none\",\"dangerouslySetInnerHTML\":{\"__html\":\"$14\"}}]]}]]}]]}],[\"$\",\"div\",\"CS\",{\"className\":\"mb-12\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-bold mb-6 text-gray-900 dark:text-white\",\"children\":\"CS\"}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-2 gap-6\",\"children\":[[\"$\",\"article\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/CS/CMD commands.md\",{\"id\":\"/Users/jeevas/Documents/Jeeva/CS Infinity/CS/CMD commands.md\",\"className\":\"bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold mb-4 text-gray-900 dark:text-white\",\"children\":\"CMD commands\"}],[\"$\",\"div\",null,{\"className\":\"prose dark:prose-invert prose-sm max-w-none\",\"dangerouslySetInnerHTML\":{\"__html\":\"$15\"}}]]}],[\"$\",\"article\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/CS/CS doubt.md\",{\"id\":\"/Users/jeevas/Documents/Jeeva/CS Infinity/CS/CS doubt.md\",\"className\":\"bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold mb-4 text-gray-900 dark:text-white\",\"children\":\"CS doubt\"}],[\"$\",\"div\",null,{\"className\":\"prose dark:prose-invert prose-sm max-w-none\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003cp\u003ein hashmap , when collosion happen , it is stored as linked list..\u003c/p\u003e\\n\u003cp\u003ebut how this more values to single key makes its usable ?\u003c/p\u003e\\n\"}}]]}],[\"$\",\"article\",\"/Users/jeevas/Documents/Jeeva/CS Infinity/CS/Files running.md\",{\"id\":\"/Users/jeevas/Documents/Jeeva/CS Infinity/CS/Files running.md\",\"className\":\"bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold mb-4 text-gray-900 dark:text-white\",\"children\":\"Files running\"}],[\"$\",\"div\",null,{\"className\":\"prose dark:prose-invert prose-sm max-w-none\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003cp\u003epython file running\u003c/p\u003e\\n\u003cp\u003epython3 filename.py\u003c/p\u003e\\n\u003cp\u003ets file running\u003c/p\u003e\\n\u003cp\u003etsc runner.ts \u0026#x26; node runner.js\u003c/p\u003e\\n\u003cp\u003ers file running\u003c/p\u003e\\n\u003cp\u003erustc runner.rs \u0026#x26;\u0026#x26; ./runner\u003c/p\u003e\\n\"}}]]}]]}]]}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"d:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nb:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"CS Infinity Notes\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"A collection of Computer Science and Programming notes\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"9:null\n"])</script></body></html>